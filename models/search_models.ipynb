{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ZMyOWfsEGS"
   },
   "source": [
    "# importing embeddings, vocabulary, & functions file\n",
    "We load the embeddings, vocabulary, and all the search functions. The functions have been predefined and are stored in the search-models subdirectory in the github repository, so we directly load them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BxoEmRAHPuDn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from search import SWOW\n",
    "from pragmatics import RSA\n",
    "from pragmatics import nonRSA\n",
    "import walker \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import walk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab is 12218 words\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('../data/walk_data/intersection_candidates.json') as json_file:\n",
    "    intersection_dict = json.load(json_file)\n",
    "with open('../data/walk_data/union_candidates.json') as json_file:\n",
    "    union_dict = json.load(json_file)\n",
    "corrections = pd.read_csv('../data/corrections.csv')\n",
    "vocab = pd.read_csv(\"../data/vocab.csv\").rename(columns={\"Word\": \"vocab_word\"})\n",
    "print(f\"vocab is {len(vocab)} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: candidate generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clueGiverID</th>\n",
       "      <th>wordpair_id</th>\n",
       "      <th>Level</th>\n",
       "      <th>clueFinal</th>\n",
       "      <th>value</th>\n",
       "      <th>clue_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454955</td>\n",
       "      <td>bowl-sun</td>\n",
       "      <td>Medium</td>\n",
       "      <td>acai</td>\n",
       "      <td>brunch,yard game,bright,acai</td>\n",
       "      <td>[brunch, yard game, bright, acai]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454955</td>\n",
       "      <td>cave-knight</td>\n",
       "      <td>Hard</td>\n",
       "      <td>mysterious</td>\n",
       "      <td>dark,dragon,unknown</td>\n",
       "      <td>[dark, dragon, unknown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>454955</td>\n",
       "      <td>glow-quick</td>\n",
       "      <td>Medium</td>\n",
       "      <td>firefly</td>\n",
       "      <td>candle,firefly,stick</td>\n",
       "      <td>[candle, firefly, stick]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454955</td>\n",
       "      <td>gold-silver</td>\n",
       "      <td>Easy</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>jewelry,metal,expensive</td>\n",
       "      <td>[jewelry, metal, expensive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>454955</td>\n",
       "      <td>oak-tree</td>\n",
       "      <td>Easy</td>\n",
       "      <td>forest</td>\n",
       "      <td>bark,forest,wood</td>\n",
       "      <td>[bark, forest, wood]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>491095</td>\n",
       "      <td>olive-real</td>\n",
       "      <td>Hard</td>\n",
       "      <td>non-GMO</td>\n",
       "      <td>organic,garden,authentic,non-GMO</td>\n",
       "      <td>[organic, garden, authentic, non-GMO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>491095</td>\n",
       "      <td>regret-rude</td>\n",
       "      <td>Hard</td>\n",
       "      <td>bully</td>\n",
       "      <td>bully,insult,fight</td>\n",
       "      <td>[bully, insult, fight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>491095</td>\n",
       "      <td>sit-stand</td>\n",
       "      <td>Easy</td>\n",
       "      <td>chair</td>\n",
       "      <td>chair,attendance,opposites,stool</td>\n",
       "      <td>[chair, attendance, opposites, stool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>491095</td>\n",
       "      <td>stern-wind</td>\n",
       "      <td>Hard</td>\n",
       "      <td>sailing</td>\n",
       "      <td>sailing,boat,gust</td>\n",
       "      <td>[sailing, boat, gust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>491095</td>\n",
       "      <td>trauma-weird</td>\n",
       "      <td>Medium</td>\n",
       "      <td>flashbacks</td>\n",
       "      <td>flashbacks,nightmares,dreams</td>\n",
       "      <td>[flashbacks, nightmares, dreams]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1456 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      clueGiverID   wordpair_id   Level   clueFinal  \\\n",
       "0          454955      bowl-sun  Medium        acai   \n",
       "1          454955   cave-knight    Hard  mysterious   \n",
       "2          454955    glow-quick  Medium     firefly   \n",
       "3          454955   gold-silver    Easy     jewelry   \n",
       "4          454955      oak-tree    Easy      forest   \n",
       "...           ...           ...     ...         ...   \n",
       "1451       491095    olive-real    Hard     non-GMO   \n",
       "1452       491095   regret-rude    Hard       bully   \n",
       "1453       491095     sit-stand    Easy       chair   \n",
       "1454       491095    stern-wind    Hard     sailing   \n",
       "1455       491095  trauma-weird  Medium  flashbacks   \n",
       "\n",
       "                                 value                              clue_list  \n",
       "0         brunch,yard game,bright,acai      [brunch, yard game, bright, acai]  \n",
       "1                  dark,dragon,unknown                [dark, dragon, unknown]  \n",
       "2                 candle,firefly,stick               [candle, firefly, stick]  \n",
       "3              jewelry,metal,expensive            [jewelry, metal, expensive]  \n",
       "4                     bark,forest,wood                   [bark, forest, wood]  \n",
       "...                                ...                                    ...  \n",
       "1451  organic,garden,authentic,non-GMO  [organic, garden, authentic, non-GMO]  \n",
       "1452                bully,insult,fight                 [bully, insult, fight]  \n",
       "1453  chair,attendance,opposites,stool  [chair, attendance, opposites, stool]  \n",
       "1454                 sailing,boat,gust                  [sailing, boat, gust]  \n",
       "1455      flashbacks,nightmares,dreams       [flashbacks, nightmares, dreams]  \n",
       "\n",
       "[1456 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_study_data = pd.read_csv('../data/exp1/e1_data.csv').melt(id_vars=['clueGiverID' , 'wordpair_id', 'Level', 'clueFinal'], value_vars=[\"clueOption1\", \"clueOption2\", \"clueOption3\", \"clueOption4\", \"clueOption5\", \"clueOption6\", \"clueOption7\", \"clueOption8\"]).rename(columns={\"value\": \"Clue1\"})\n",
    "generation_study_data = nonRSA.apply_corrections(generation_study_data, corrections, vocab)\n",
    "generation_study_data = generation_study_data.dropna().drop_duplicates().groupby(['clueGiverID','wordpair_id',  'Level', 'clueFinal'], as_index=False)['correctedClue'].agg(','.join)\n",
    "generation_study_data['clue_list'] = generation_study_data['value'].str.split(',')\n",
    "display(generation_study_data)\n",
    "common_candidates = nonRSA.get_common_candidates(union_dict, intersection_dict, generation_study_data, '../data/exp1/e1_common_candidates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: original connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word1     Word2 Experiment        boardnames   Level         wordpair\n",
      "0     void     couch         E1   e1_board1_words    Hard       void-couch\n",
      "1   giggle  abnormal         E1   e1_board1_words  Medium  giggle-abnormal\n",
      "2     exam   algebra         E1   e1_board1_words    Easy     exam-algebra\n",
      "3      tea      bean         E1  e1_board10_words    Easy         tea-bean\n",
      "4  tourist    comedy         E1  e1_board10_words  Medium   tourist-comedy\n",
      "embeddings are shaped: (12218, 300)\n"
     ]
    }
   ],
   "source": [
    "e2_data = pd.read_csv(\"../data/exp2/e2_empirical_clues.csv\", encoding= 'unicode_escape')\n",
    "target_df = pd.read_csv(\"../data/targets.csv\")\n",
    "print(target_df.head())\n",
    "representations = {}\n",
    "representations['swow'] = pd.read_csv(\"../data/swow_associative_embeddings.csv\").transpose().values\n",
    "print(f\"embeddings are shaped:\", representations['swow'].shape)\n",
    "with open('../data/exp2/e2_boards.json', 'r') as json_file:\n",
    "    e2_boards = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non-RSA\n",
    "\n",
    "Here we import the candidates from the json files and first compute how the non-RSA model would rank these candidates for each budget level. Next, we merge these obtained probabilities with the actual behavioral data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_optimal_params = {\n",
    "    'swow' : (23.488850322875496, 1), # -13204\n",
    "    'glove' : (20.952928531665275, 1), # -15774.814774380024)\n",
    "    'bert-sum' : (19.983835225540847, 0.787924454045298),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_x</th>\n",
       "      <th>Board</th>\n",
       "      <th>Word1_x</th>\n",
       "      <th>Word2_x</th>\n",
       "      <th>Clue1</th>\n",
       "      <th>clueCount</th>\n",
       "      <th>wordpair</th>\n",
       "      <th>correctedClue</th>\n",
       "      <th>Word1_y</th>\n",
       "      <th>Word2_y</th>\n",
       "      <th>Experiment_y</th>\n",
       "      <th>boardnames</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>calculus</td>\n",
       "      <td>1</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>calculus</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>equation</td>\n",
       "      <td>1</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>equation</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>1</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>math</td>\n",
       "      <td>22</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>math</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>school</td>\n",
       "      <td>2</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>school</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment_x       Board Word1_x  Word2_x      Clue1  clueCount  \\\n",
       "0           E1  TrialList1    exam  algebra   calculus          1   \n",
       "1           E1  TrialList1    exam  algebra   equation          1   \n",
       "2           E1  TrialList1    exam  algebra  knowledge          1   \n",
       "3           E1  TrialList1    exam  algebra       math         22   \n",
       "4           E1  TrialList1    exam  algebra     school          2   \n",
       "\n",
       "       wordpair correctedClue Word1_y  Word2_y Experiment_y       boardnames  \\\n",
       "0  exam-algebra      calculus    exam  algebra           E1  e1_board1_words   \n",
       "1  exam-algebra      equation    exam  algebra           E1  e1_board1_words   \n",
       "2  exam-algebra     knowledge    exam  algebra           E1  e1_board1_words   \n",
       "3  exam-algebra          math    exam  algebra           E1  e1_board1_words   \n",
       "4  exam-algebra        school    exam  algebra           E1  e1_board1_words   \n",
       "\n",
       "  Level  \n",
       "0  Easy  \n",
       "1  Easy  \n",
       "2  Easy  \n",
       "3  Easy  \n",
       "4  Easy  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_data = nonRSA.apply_corrections(e2_data, corrections, vocab)\n",
    "e2_data['wordpair'] = e2_data['wordpair'].str.replace(' ', '')\n",
    "e2_data = e2_data.merge(target_df, on='wordpair', how='left')\n",
    "e2_data.to_csv(\"../data/exp2/e2_corrected.csv\", index=False)\n",
    "e2_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateprobs_nonRSA  = nonRSA.get_nonRSA_union_int(union_dict, intersection_dict, target_df, e2_boards, board_optimal_params, vocab, representations, e2_data, '../data/exp2/nonRSAprobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_optimal_params = {\n",
    "    'swow' : (25.1522030761838, 0.03863169001849234),\n",
    "    'glove' : (82.83019661384789, 0.9997249702731884),\n",
    "    'bert-sum' : (29.709602301411962, 0.031659060110267576), #-17533\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateprobs_RSA  = RSA.get_RSA_union_int(union_dict, intersection_dict, target_df, e2_boards, rsa_optimal_params, vocab, representations, e2_data, '../data/exp2/RSAprobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: targeted endorsements\n",
    "Here, we look at how the models predict specific target endorsements from the candidate set provided to the speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wordpair</th>\n",
       "      <th>accessibility</th>\n",
       "      <th>distinctiveness</th>\n",
       "      <th>Clue1</th>\n",
       "      <th>Word1_x</th>\n",
       "      <th>Word2_x</th>\n",
       "      <th>Board</th>\n",
       "      <th>Experiment_x</th>\n",
       "      <th>correctedClue</th>\n",
       "      <th>correctedClue_in_vocab</th>\n",
       "      <th>Word1_y</th>\n",
       "      <th>Word2_y</th>\n",
       "      <th>Experiment_y</th>\n",
       "      <th>boardnames</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>school</td>\n",
       "      <td>EXAM</td>\n",
       "      <td>ALGEBRA</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>E1</td>\n",
       "      <td>school</td>\n",
       "      <td>True</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>calculus</td>\n",
       "      <td>EXAM</td>\n",
       "      <td>ALGEBRA</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>E1</td>\n",
       "      <td>calculus</td>\n",
       "      <td>True</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>test</td>\n",
       "      <td>EXAM</td>\n",
       "      <td>ALGEBRA</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>E1</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>math</td>\n",
       "      <td>EXAM</td>\n",
       "      <td>ALGEBRA</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>E1</td>\n",
       "      <td>math</td>\n",
       "      <td>True</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>giggle-abnormal</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>funny</td>\n",
       "      <td>GIGGLE</td>\n",
       "      <td>ABNORMAL</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>E1</td>\n",
       "      <td>funny</td>\n",
       "      <td>True</td>\n",
       "      <td>giggle</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wordpair accessibility distinctiveness     Clue1 Word1_x   Word2_x  \\\n",
       "0     exam-algebra          high            high    school    EXAM   ALGEBRA   \n",
       "1     exam-algebra           low             low  calculus    EXAM   ALGEBRA   \n",
       "2     exam-algebra          high             low      test    EXAM   ALGEBRA   \n",
       "3     exam-algebra           low            high      math    EXAM   ALGEBRA   \n",
       "4  giggle-abnormal          high            high     funny  GIGGLE  ABNORMAL   \n",
       "\n",
       "        Board Experiment_x correctedClue  correctedClue_in_vocab Word1_y  \\\n",
       "0  TrialList1           E1        school                    True    exam   \n",
       "1  TrialList1           E1      calculus                    True    exam   \n",
       "2  TrialList1           E1          test                    True    exam   \n",
       "3  TrialList1           E1          math                    True    exam   \n",
       "4  TrialList1           E1         funny                    True  giggle   \n",
       "\n",
       "    Word2_y Experiment_y       boardnames   Level  \n",
       "0   algebra           E1  e1_board1_words    Easy  \n",
       "1   algebra           E1  e1_board1_words    Easy  \n",
       "2   algebra           E1  e1_board1_words    Easy  \n",
       "3   algebra           E1  e1_board1_words    Easy  \n",
       "4  abnormal           E1  e1_board1_words  Medium  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/exp3/e3_boards.json', 'r') as json_file:\n",
    "    e3_boards = json.load(json_file)\n",
    "e3_stimuli = pd.read_csv('../data/exp3/e3_stimuli.csv')\n",
    "## pass through corrections file\n",
    "e3_stimuli = nonRSA.apply_corrections(e3_stimuli, corrections, vocab)\n",
    "# create column that records whether correctedClue in vocab or not\n",
    "e3_stimuli['correctedClue_in_vocab'] = e3_stimuli['correctedClue'].isin(vocab['vocab_word'])\n",
    "# merge with target_df\n",
    "e3_stimuli = e3_stimuli.merge(target_df, on='wordpair', how='left')\n",
    "e3_stimuli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non-RSA probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_nonRSA = nonRSA.get_nonRSA_union_int(union_dict, intersection_dict, target_df, e3_boards, board_optimal_params, vocab, representations, e3_stimuli, '../data/exp3/nonRSAprobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_nonRSA  = RSA.get_RSA_union_int(union_dict, intersection_dict, target_df, e3_boards, rsa_optimal_params, vocab, representations, e3_stimuli, '../data/exp3/RSAprobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turbine', 'turbinate', 'urine']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for finding closest matches to a given word (spell-check)\n",
    "from english_words import english_words_set\n",
    "'imitate' in english_words_set\n",
    "import difflib\n",
    "difflib.get_close_matches('turbine', list(english_words_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdata_long = e3_stimuli.groupby(['wordpair'], as_index=False)['value'].agg(','.join)\n",
    "expdata_long['clue_list'] = expdata_long['value'].str.split(',')\n",
    "expdata_long = expdata_long.merge(target_df, on = \"wordpair\")\n",
    "# count how many clues for each wordpair are not in vocab\n",
    "expdata_long['len_cluelist_not_in_vocab'] = expdata_long['clue_list'].apply(lambda x: len([e for e in x if e not in list(vocab.vocab_word)]))\n",
    "expdata_long_subset = expdata_long[expdata_long['len_cluelist_not_in_vocab'] == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qt6jgRIeM7YO"
   },
   "source": [
    "# Old: Dedicated functions for full vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5gKTDYETeKlH"
   },
   "outputs": [],
   "source": [
    "## create boards and merge with expdata\n",
    "combined_boards_df = pd.DataFrame(columns=['Experiment', 'Board','boardwords'])\n",
    "combined_boards_df[\"Experiment\"]  = [\"E1\"] * 10 + [\"E2\"] * 10\n",
    "combined_boards_df[\"Board\"] = [\"TrialList\" + str(i) for i in range(1,11)] * 2\n",
    "combined_boards_df[\"boardnames\"] = (['e1_board' + str(i) + '_words' for i in range(1,11)] \n",
    "                                  + ['e2_board' + str(i) + '_words' for i in range(1,11)])\n",
    "combined_boards_df[\"boardwords\"] = [boards[n] for n in combined_boards_df[\"boardnames\"]]\n",
    "\n",
    "expdata_new = pd.merge(expdata,combined_boards_df,on=['Board', 'Experiment'],how='left')\n",
    "expdata_new[\"wordpair\"] = expdata_new[\"Word1\"] + \"-\" + expdata_new[\"Word2\"]\n",
    "board_combos = {board_name : search_funcs.RSA.compute_board_combos(board_name, boards) for board_name in boards.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZOYctgjM5NM"
   },
   "source": [
    "## Non - RSA method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "v8QEomkF4hmB"
   },
   "outputs": [],
   "source": [
    "board_optimal_params = {\n",
    "    'swow' : (23.488850322875496, 1), # -13204\n",
    "    'glove' : (20.952928531665275, 1), # -15774.814774380024)\n",
    "    'bert-sum' : (19.983835225540847, 0.787924454045298),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9r7kmGrcNCvB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for swow and alpha 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cluescoredf \u001b[38;5;241m=\u001b[39m \u001b[43msearch_funcs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonRSA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_targetboard_cluescores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mswow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglove\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard_optimal_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard_combos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_word\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepresentations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpdata_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cluescoredf\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Repos/Connector/search-models/search_funcs.py:677\u001b[0m, in \u001b[0;36mnonRSA.speaker_targetboard_cluescores\u001b[0;34m(modelnames, optimal_params, board_combos, boards, candidates, vocab, representations, target_df, cluedata)\u001b[0m\n\u001b[1;32m    674\u001b[0m beta \u001b[38;5;241m=\u001b[39m optimal_params[modelname][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and alpha \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 677\u001b[0m speaker_board_probs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    678\u001b[0m     board_name : nonRSA\u001b[38;5;241m.\u001b[39mspeaker_targetboard(boards[board_name], alpha, beta, candidates, representations, modelname, vocab, target_df)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m board_name \u001b[38;5;129;01min\u001b[39;00m boards\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    680\u001b[0m }   \n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m board \u001b[38;5;129;01min\u001b[39;00m speaker_board_probs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    683\u001b[0m   \n\u001b[1;32m    684\u001b[0m   \u001b[38;5;66;03m## get the clues we need scores for from expdatanew\u001b[39;00m\n\u001b[1;32m    685\u001b[0m   clue_main \u001b[38;5;241m=\u001b[39m cluedata\u001b[38;5;241m.\u001b[39mloc[cluedata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboardnames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m board]\n",
      "File \u001b[0;32m~/Repos/Connector/search-models/search_funcs.py:678\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    674\u001b[0m beta \u001b[38;5;241m=\u001b[39m optimal_params[modelname][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and alpha \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    677\u001b[0m speaker_board_probs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 678\u001b[0m     board_name : \u001b[43mnonRSA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_targetboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboards\u001b[49m\u001b[43m[\u001b[49m\u001b[43mboard_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepresentations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m board_name \u001b[38;5;129;01min\u001b[39;00m boards\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    680\u001b[0m }   \n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m board \u001b[38;5;129;01min\u001b[39;00m speaker_board_probs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    683\u001b[0m   \n\u001b[1;32m    684\u001b[0m   \u001b[38;5;66;03m## get the clues we need scores for from expdatanew\u001b[39;00m\n\u001b[1;32m    685\u001b[0m   clue_main \u001b[38;5;241m=\u001b[39m cluedata\u001b[38;5;241m.\u001b[39mloc[cluedata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboardnames\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m board]\n",
      "File \u001b[0;32m~/Repos/Connector/search-models/search_funcs.py:628\u001b[0m, in \u001b[0;36mnonRSA.speaker_targetboard\u001b[0;34m(context_board, alpha, beta, candidates, representations, modelname, vocab, target_df)\u001b[0m\n\u001b[1;32m    623\u001b[0m board_vectors \u001b[38;5;241m=\u001b[39m representations[modelname][board_word_indices]\n\u001b[1;32m    625\u001b[0m \u001b[38;5;66;03m## clue_sims is the similarity of ALL clues in full searchspace (size N) to EACH word on board (size 20)\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m### NEED TO FIX THIS TO ONLY CONSIDER CANDIDATES!!\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m candidate_index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_word\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mindex(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[1;32m    629\u001b[0m candidate_embeddings \u001b[38;5;241m=\u001b[39m representations[modelname][candidate_index]\n\u001b[1;32m    631\u001b[0m clue_sims \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mscipy\u001b[38;5;241m.\u001b[39mspatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mcdist(board_vectors, candidate_embeddings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Repos/Connector/search-models/search_funcs.py:628\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    623\u001b[0m board_vectors \u001b[38;5;241m=\u001b[39m representations[modelname][board_word_indices]\n\u001b[1;32m    625\u001b[0m \u001b[38;5;66;03m## clue_sims is the similarity of ALL clues in full searchspace (size N) to EACH word on board (size 20)\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m### NEED TO FIX THIS TO ONLY CONSIDER CANDIDATES!!\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m candidate_index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvocab_word\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mindex(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[1;32m    629\u001b[0m candidate_embeddings \u001b[38;5;241m=\u001b[39m representations[modelname][candidate_index]\n\u001b[1;32m    631\u001b[0m clue_sims \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mscipy\u001b[38;5;241m.\u001b[39mspatial\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mcdist(board_vectors, candidate_embeddings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m ) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cluescoredf = nonRSA.speaker_targetboard_cluescores(['swow', 'glove'], board_optimal_params, board_combos, boards, list(vocab.vocab_word), vocab, representations, target_df, expdata_new)\n",
    "cluescoredf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67827P5C897A"
   },
   "source": [
    "## RSA Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVrhPE-xN6I4"
   },
   "outputs": [],
   "source": [
    "rsa_optimal_params = {\n",
    "    'swow' : (25.1522030761838, 0.03863169001849234),\n",
    "    'glove' : (22.336514544537227, 0.039),\n",
    "    'bert-sum' : (29.709602301411962, 0.031659060110267576), #-17533\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ewq3Y68zSd_H"
   },
   "outputs": [],
   "source": [
    "pragmaticspeakerdf = search_funcs.RSA.get_speaker_df(representations, combined_boards_df,rsa_optimal_params, list(vocab.vocab_word), vocab, expdata_new, board_combos, target_df, boards)\n",
    "pragmaticspeakerdf.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPN3gA5HcesL1IibYO9jUBA",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "search-models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
