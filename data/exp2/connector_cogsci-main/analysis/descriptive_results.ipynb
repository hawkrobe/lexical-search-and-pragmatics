{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2mrakjwArhU"
   },
   "source": [
    "# File and GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1627755866216,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "bDhQiyrA_1g9"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import scipy.spatial.distance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import randint\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from numpy.linalg import matrix_power\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627755866217,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "0vwbV_eh_3Wu",
    "outputId": "7d8e5866-8bc0-4b6d-dc3d-6a3be1c911c0"
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"../data/vocab.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS9JyrlwA0D2"
   },
   "source": [
    "# Constructing word similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each of 12218 words, we have (1) glove, (2) SWOW, and (3) non-contextual BERT embeddings\n",
    "(swow has 2 versions : PPMI and Random Walk) -- we use RW \n",
    "bert context-free embeddings obtained by \"CLS [word] SEP\": summed across last four layers (768-dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9057,
     "status": "ok",
     "timestamp": 1627755875270,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "RqwfQyU3_5CD"
   },
   "outputs": [],
   "source": [
    "representations = {}\n",
    "representations['glove'] = pd.read_csv(\"../data/glove_embeddings.csv\").transpose().values\n",
    "representations['swow'] = pd.read_csv(\"../data/swow_embeddings.csv\").transpose().values\n",
    "representations['bert-sum'] = pd.read_csv(\"../data/bert_embeddings.csv\").transpose().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_similarity_matrix(vector1, vector2, N):\n",
    "    N = len(vector1)\n",
    "    M = len(vector2)\n",
    "    dist = scipy.spatial.distance.cdist(vector1, vector2, 'cosine')\n",
    "    return 1 - dist.reshape(-1).reshape((N,M))\n",
    "\n",
    "sim_matrices = {}\n",
    "sim_matrices['glove'] = create_similarity_matrix(representations['glove'], representations['glove'], )\n",
    "sim_matrices['swow'] = create_similarity_matrix(representations['swow'], representations['swow'], len(representations['swow']))\n",
    "sim_matrices['bert-sum'] = create_similarity_matrix(representations['bert-sum'], representations['bert-sum'], len(representations['bert-sum']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1627760588954,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "lqQ0AmLNANTd",
    "outputId": "5d814931-1989-4006-86b5-6e31f4894d9a"
   },
   "outputs": [],
   "source": [
    "print('representation shape', representations['swow'].shape)\n",
    "print('similarity matrix shape', sim_matrices['swow'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pgtW9bkAooh"
   },
   "source": [
    "# Importing Empirical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1627755875272,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "IUuVeaRyAiik",
    "outputId": "a38d5770-b9a3-4714-842f-d6aa2f604a52"
   },
   "outputs": [],
   "source": [
    "## only keeping columns we need here\n",
    "rawdata = pd.read_csv(\"../data/raw_data.csv\")\n",
    "rawdata = rawdata[rawdata.columns[3:37]]\n",
    "print(f\"our data has {len(rawdata)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex7LB885Dkdu"
   },
   "source": [
    "# Defining composite vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9DO9zE15QDq"
   },
   "source": [
    "we construct a baseline model based on simply the average vector of W1 and W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1627756495557,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "LIMRZmU9B86S",
    "outputId": "66398d8b-48c6-40c8-df0d-260b86bfd0a5"
   },
   "outputs": [],
   "source": [
    "def average_vec(word1, word2, labels_df, embeddings, embeddingsize):\n",
    "    word1_index = list(labels_df[\"Word\"]).index(word1)\n",
    "    word2_index = list(labels_df[\"Word\"]).index(word2)\n",
    "\n",
    "    word1_vector = embeddings[word1_index]\n",
    "    word2_vector = embeddings[word2_index]\n",
    "\n",
    "    avg_vector = (word1_vector + word2_vector)/2\n",
    "    avg_vector = avg_vector.reshape((1, embeddingsize))\n",
    "\n",
    "    return avg_vector\n",
    "\n",
    "avg = average_vec(\"apple\", \"mango\", sample_df, representations['glove'], 300)\n",
    "1 - scipy.spatial.distance.cdist(representations['glove'][list(sample_df[\"Word\"]).index(\"apple\")].reshape((1,300)), avg.reshape((1,300)), 'cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XU5Z4GU5Ta8"
   },
   "source": [
    "also the average of W1, W2, and Clue1 (for feedback analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1627756496369,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "SMNrHDyvFCia",
    "outputId": "dfd91f49-b2cb-4076-ed81-1071517d8118"
   },
   "outputs": [],
   "source": [
    "def w1w2c1_vec(word1, word2, clue1, labels_df, embeddings, embeddingsize):\n",
    "    word1_index = list(labels_df[\"Word\"]).index(word1)\n",
    "    word2_index = list(labels_df[\"Word\"]).index(word2)\n",
    "    clue1_index = list(labels_df[\"Word\"]).index(clue1)\n",
    "\n",
    "    word1_vector = embeddings[word1_index]\n",
    "    word2_vector = embeddings[word2_index]\n",
    "    clue1_vector = embeddings[clue1_index]\n",
    "\n",
    "    avg_vector = (word1_vector + word2_vector + clue1_vector)/3\n",
    "    avg_vector = avg_vector.reshape((1,embeddingsize))\n",
    "\n",
    "    return avg_vector\n",
    "\n",
    "w1w2c1_vec(\"lion\", \"tiger\", \"animal\", sample_df, representations['glove'], 300).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxpSAFK65XSM"
   },
   "source": [
    "## Constructing all combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize with NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindata_sample = rawdata.copy()\n",
    "for representation in ['bert-sum', 'glove', 'swow'] : \n",
    "    for col in ['w1w2', 'c1w1', 'c1w2', 'c1avg', 'c2w1', 'c2w2', 'c2_w1w2avg', 'c2_c1avg'] :\n",
    "        maindata_sample[representation + \"_\" + col + \"_sim\"] = 'NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EoEOsfb5Y_9"
   },
   "source": [
    "Now computes the similarities of differnet words/clues by looping through the empirical data. Note that the \"embedding\" and \"sim_matrix\" variables are changed at the beginning of the loop and the columns corresponding to each embedding are appended one after the other (i.e., this cell needs to run 3 times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "executionInfo": {
     "elapsed": 30880,
     "status": "ok",
     "timestamp": 1627756800544,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "5c1iLbqQDwYo",
    "outputId": "dbfaca4a-9a2b-4e9d-ae1a-a3ea81d771bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for representation in ['bert-sum', 'glove', 'swow'] :\n",
    "    embedding = representations[representation]\n",
    "    embeddingsize = embedding.shape[1]\n",
    "    sim_matrix = sim_matrices[representation]\n",
    "    for index, row in maindata_sample.iterrows():\n",
    "        word1 = str(row[\"Word1\"])\n",
    "        word2 = str(row[\"Word2\"])\n",
    "        clue1 = str(row[\"Clue1\"])\n",
    "        clue2 = str(row[\"Clue2\"])\n",
    "\n",
    "        if word1 in list(sample_df[\"Word\"]) and word2 in list(sample_df[\"Word\"]):\n",
    "            w1_index = list(sample_df[\"Word\"]).index(word1) \n",
    "            w2_index = list(sample_df[\"Word\"]).index(word2)\n",
    "            maindata_sample.loc[index, representation + \"_w1w2_sim\"] = sim_matrix[w1_index, w2_index]\n",
    "            if clue1 in list(sample_df[\"Word\"]):\n",
    "                c1_index = list(sample_df[\"Word\"]).index(clue1)\n",
    "                w1w2avg = average_vec(word1, word2, sample_df, embedding, embeddingsize)\n",
    "                maindata_sample.loc[index,representation + \"_c1w1_sim\"] = sim_matrix[w1_index, c1_index]\n",
    "                maindata_sample.loc[index,representation + \"_c1w2_sim\"] = sim_matrix[w2_index, c1_index]\n",
    "                maindata_sample.loc[index,representation + \"_c1avg_sim\"] = (1 - scipy.spatial.distance.cdist(embedding[c1_index].reshape((1,embeddingsize)), w1w2avg.reshape((1,embeddingsize)), 'cosine')).tolist()[0][0]\n",
    "\n",
    "            if clue2 in list(sample_df[\"Word\"]):\n",
    "                c2_index = list(sample_df[\"Word\"]).index(clue2)\n",
    "                w1w2avg = average_vec(word1, word2, sample_df, embedding, embeddingsize)\n",
    "                c2_w1w2avg_sim = scipy.spatial.distance.cdist(embedding[c2_index].reshape((1,embeddingsize)), w1w2avg.reshape((1,embeddingsize)), 'cosine')\n",
    "                maindata_sample.loc[index,representation + \"_c2w1_sim\"] = sim_matrix[w1_index, c2_index]\n",
    "                maindata_sample.loc[index,representation + \"_c2w2_sim\"] = sim_matrix[w2_index, c2_index]\n",
    "                maindata_sample.loc[index,representation + \"_c2_w1w2avg_sim\"] = 1 - c2_w1w2avg_sim.tolist()[0][0]\n",
    "                if clue1 in list(sample_df[\"Word\"]):\n",
    "                    c1avg_vec = w1w2c1_vec(word1, word2, clue1, sample_df, embedding,embeddingsize)\n",
    "                    c2_c1avg_sim = scipy.spatial.distance.cdist(embedding[c2_index].reshape((1,embeddingsize)), c1avg_vec.reshape((1,embeddingsize)), 'cosine')\n",
    "                    maindata_sample.loc[index,representation + \"_c2_c1avg_sim\"] = 1 - c2_c1avg_sim.tolist()[0][0]\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindata_sample['bert-sum_w1w2_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1627756871394,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 240
    },
    "id": "-pSBo36NIbBF"
   },
   "outputs": [],
   "source": [
    "maindata_sample.to_csv(\"../data/descriptive_precomputed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFjMYAxbFP7Q"
   },
   "source": [
    "These estimates will now be analysed in a separate Rmd file."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPptfL+hBnEl9sN8aMoPLfP",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cogsci_descriptive_analyses_abhilasha.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
