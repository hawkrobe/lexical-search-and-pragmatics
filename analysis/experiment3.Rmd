---
title: "Search and pragmatics in Connector"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Imports

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggthemes)
library(tidyboot)
library(here)
library(jsonlite)
library(lme4)
library(broom.mixed)
setwd(here::here())
getwd()
library(ggrepel)
```

# behavioral data 

## import listener data (for Level recoding)

```{r}
listener = read_csv("../data/exp3/listener.csv") %>% 
  filter(typeoftrial %in% c("guess1", "guess2") & 
           accessibility %in% c("high", "low")) %>% 
  # excluding second attempt of 61440, identified by a different timestamp 
  filter(subject != 43110)

num_trials = listener %>%
  group_by(sona_id)%>%
  summarise(trials = n()) # should not exceed 480

## making data wide and calculating accuracy

data_wide = listener %>% 
  dplyr::select(sona_id, typeoftrial, wordpair, clue, accessibility, distinctiveness,
                            Board, Experiment, guess) %>%
  pivot_wider(names_from = "typeoftrial", values_from  = "guess") %>%
  mutate(accuracy = ifelse((str_detect(wordpair, tolower(guess1)) & 
                              str_detect(wordpair, tolower(guess2))), 1, 0))

subject_acc = data_wide %>%
  group_by(sona_id)%>%
  summarise_at(vars(accuracy), mean) %>%
  rename(mean_accuracy = accuracy)

num_trials = data_wide %>%
  group_by(sona_id)%>%
  summarise(trials = n())

exclude_subjects = unique(c((subject_acc %>% filter(mean_accuracy < .10))$sona_id,
                         (num_trials %>% filter(trials != 240))$sona_id))

## exclude <10% accuracy participants (pre-registered criterion)

data_wide = data_wide  %>% filter(!sona_id %in% exclude_subjects)%>%
  mutate(wordpair = tolower(gsub(" ", "", wordpair, fixed = TRUE)),
         clue = tolower(clue))

length(unique(data_wide$sona_id)) ## final N=31

# get mean accuracy per wordpair

wordpair_accuracy = data_wide %>% group_by(wordpair) %>%
  summarize(correct = mean(accuracy)) %>%
  mutate(Level = case_when(correct < .13 ~ 'Hard',
                           correct > .25 ~ 'Easy',
                           TRUE ~ 'Medium')) %>%
  mutate(Level = fct_relevel(Level, 'Easy', 'Medium', 'Hard'))

## histogram of wordpair_accuracy

wordpair_accuracy %>%
  ggplot(aes(x = correct*100, fill = Level)) +
    geom_histogram(bins = 30) +
    geom_vline(xintercept = c(14,25)) +
    labs(x = '% correct') +
    theme_few() +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave(here('analysis/plots/e3_difficulty_dist.pdf'), units = 'in', width = 7, height = 4)



num_level = wordpair_accuracy %>% group_by(Level) %>% count() %>% 
  ungroup() %>%
  mutate(percent = n / sum(n))

## RTs

listener %>% 
  dplyr::select(sona_id, typeoftrial, wordpair, clue, rt) %>%
  pivot_wider(names_from = "typeoftrial", values_from  = "rt")%>%
  left_join(wordpair_accuracy) %>%
  mutate(guess1 = as.numeric(guess1), guess2 = as.numeric(guess2)) %>%
  rowwise()%>%
  mutate(mean_rt = (guess1+ guess2)/2)%>%
  group_by(Level) %>% tidyboot_mean(mean_rt, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean time to select word pairs (ms)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave(here('analysis/plots/exp3_generation_time.pdf'), units = 'in', width = 4, height = 4)

## mean accuracy per clue 

clue_accuracy = data_wide %>% group_by(wordpair, clue) %>%
  summarize(correct = mean(accuracy))



```

## import speaker data

```{r}
raw_data = read_csv("../data/exp3/raw.csv") %>% 
  group_by(sona_id) %>%
  mutate(min_recorded_at = min(recorded_at)) %>%
  ungroup() %>%
  filter(recorded_at == min_recorded_at)%>%
  mutate(wordpair = gsub(' - ', '-', wordpair),
         response = as.numeric(response)) 

original_N = raw_data %>% pull(sona_id) %>% unique() %>% length()

e3_data = raw_data %>% 
  select(sona_id, subject, typeoftrial,wordpair, Clue1, correctedClue,  response, rt, condition, 
        accessibility, distinctiveness,  recorded_at)%>%
  filter(!is.na(wordpair) & accessibility != "prac") %>%
  rename(clue = "Clue1")

incomplete_IDs = e3_data %>% group_by(sona_id) %>% count() %>% filter(n < 240) %>% pull(sona_id)

mean_ratings_IDs = e3_data %>% group_by(sona_id) %>% 
  summarise(mean_rating = mean(response)) %>% filter(mean_rating < 1.5) %>% pull(sona_id)

final_data = e3_data %>% filter(!sona_id %in% c(incomplete_IDs, mean_ratings_IDs)) %>%
  mutate(wordpair = tolower(wordpair))
N = final_data %>% pull(sona_id) %>% unique() %>% length()
final_IDs = final_data %>% pull(sona_id) %>% unique()


num_ratings_per_pair = final_data %>% group_by(wordpair, sona_id) %>%
  count() 

ratings = final_data %>%
  group_by(wordpair, correctedClue) %>%
  # average all the rating scores, higher sum total means that clue was most preferred
  # across all participants
  summarise_at(vars(response), mean)%>%
  ungroup()%>%
  group_by(wordpair) %>%
  mutate(z_rating = as.numeric(scale(response)))

# ratings by level


final_data %>% left_join(wordpair_accuracy) %>%
  group_by(Level) %>% tidyboot_mean(response, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean rating (1-5)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

  
ggsave(here('analysis/plots/exp3_rating_plot.pdf'), units = 'in', width = 4, height = 4)

# RTs by level

final_data %>% left_join(wordpair_accuracy) %>%
  group_by(Level) %>% tidyboot_mean(rt, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean time to rate clues (ms)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave(here('analysis/plots/exp3_rating_time.pdf'), units = 'in', width = 4, height = 4)


```

## speaker-listener pattern

```{r}

original_ratings = final_data %>%
  group_by(wordpair, clue) %>%
  # average all the rating scores, higher sum total means that clue was most preferred
  # across all participants
  summarise_at(vars(response), mean)%>%
  ungroup()%>%
  group_by(wordpair) %>%
  mutate(z_rating = as.numeric(scale(response)))

speaker_listener = clue_accuracy %>% left_join(original_ratings) %>%
  left_join(wordpair_accuracy %>% select(-correct))%>%
  mutate(x = paste0(wordpair, ":", clue))

label_data= speaker_listener %>% 
  filter(wordpair %in% c("lion-tiger", "weird-trauma", "war-quiet"))

speaker_listener %>%
  ggplot(aes(x = response, y = correct, group = Level, color = Level)) +
  geom_point(alpha = 0.15)+
  geom_smooth(method = "lm")+
  geom_text_repel(
    data = label_data,
    aes(label = clue), box.padding = 0.15, point.padding = 0.15, 
    max.overlaps = Inf, segment.color = NA, fontface = "bold") +
  scale_y_continuous(limits = c(0,1))+
  scale_x_continuous(limits = c(1,5))+
  theme_few() +
  scale_color_manual(values = c('#60BD68', '#BAB504', '#CC253D'))+
    labs(x = "speaker ratings (1-5)", y = "listener accuracy") +
    theme(aspect.ratio = 1)

behavioral_model = lm(data = speaker_listener, correct ~ response*Level)
summary(behavioral_model)

ggsave('plots/exp3_speaker_listener.pdf', units = 'in', width = 5, height = 5)

  
```




# model comparisons

## import model probs

```{r}
# clue_subset_dfs = paste0(getwd(),"/data/exp3/model_output/diagnostic_subset/")
# full_vocab_dfs = paste0(getwd(),"/data/exp3/model_output/diagnostic_full/")
# 
# # Assuming cost_fn needs to be converted to numeric (double)
# speaker_dfs <- rbind(map_dfr(list.files(path = full_vocab_dfs, pattern = "\\.csv$", full.names = TRUE), 
#                       ~read_csv(.x) %>% mutate(cost_fn = as.numeric(cost_fn))) %>% mutate(type = "1: full vocab"),
#                      map_dfr(list.files(path = clue_subset_dfs, pattern = "\\.csv$", full.names = TRUE), 
#                       ~read_csv(.x) %>% mutate(cost_fn = as.numeric(cost_fn))) %>% mutate(type = "2: clue subset")) 
# 
# write.csv(speaker_dfs, file = paste0(getwd(),"/data/exp3/model_output/all_speaker_dfs.csv"), row.names = FALSE)

speaker_dfs = read_csv("data/exp3/model_output/all_speaker_dfs.csv", row.names = FALSE)
model_plus_ratings = speaker_dfs %>% mutate(wordpair = tolower(wordpair)) %>%
  left_join(ratings) %>% 
  filter(!is.na(prob)) %>%
  select(type, wordpair, correctedClue, model, alpha, costweight, distweight,  cost_fn, prob, z_rating) %>%
  left_join(wordpair_accuracy %>% select(wordpair, Level))

```
## correlations for speaker ratings
```{r}
# get correlation between each model and z-ratings

spearman = model_plus_ratings %>%
  # calculate correlation for each model subtype at the wordpair level
  group_by(Level, wordpair, type,  model,alpha, cost_fn,  costweight, distweight) %>%
  summarise(r = cor(prob, z_rating, method = "spearman"),
            n= n())%>%
  mutate(informativity = sub("cdf|freq", "", model),
          cost_source= sub(".*(cdf|freq)", "\\1", model))


kendall = model_plus_ratings %>%
  # calculate correlation for each model subtype at the wordpair level
  group_by(Level, wordpair, type,  model,alpha, cost_fn,  costweight, distweight) %>%
  summarise(r = cor(prob, z_rating, method = "kendall"),
            n= n())%>%
  mutate(informativity = sub("cdf|freq", "", model),
          cost_source= sub(".*(cdf|freq)", "\\1", model))


avg_corr_df = rbind(kendall %>% mutate(cortype = "kendall"), 
                       spearman %>% mutate(cortype = "spearman")) %>%
  filter(!is.na(r))%>%
  group_by(Level, type,  model,alpha, cost_fn,  costweight, distweight, cortype) %>%
  # average across different costweights and distweights
  summarize(avg_r = mean(r, na.rm = TRUE),
            ci_lower = mean(r) - 2*sd(r)/sqrt(length(r)),
            ci_upper= mean(r) + 2*sd(r)/sqrt(length(r))) 

max_cor_df =avg_corr_df %>%
  ungroup() %>% group_by(Level, cortype) %>%
  filter(avg_r == max(avg_r))%>%
  arrange(Level, desc(avg_r))
    
ggsave(here('analysis/plots/exp3_model_comparisons.pdf'), units = 'in', height = 3, width = 6)

```

## heatmap

```{r}
  
plot1 = avg_corr_df %>%
  filter(cortype == "spearman", model == "RSAcdf", type == "1: full vocab") %>%
  ggplot(aes(x = costweight, y = distweight, fill = avg_r)) +
  geom_tile()+
    scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
      geom_point(data = . %>% group_by(Level) %>%
  filter(avg_r == max(avg_r)), color = "black", size = 1)+
  facet_grid(Level~cost_fn)+
  theme_few() +
    labs(title = "spearman RSA cdf")+
    theme(aspect.ratio = 1)

plot2 = avg_corr_df %>%
  filter(cortype == "spearman", model == "additivecdf", type == "1: full vocab") %>%
  ggplot(aes(x = costweight, y = distweight, fill = avg_r)) +
  geom_tile()+
    scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
      geom_point(data = . %>% group_by(Level) %>%
  filter(avg_r == max(avg_r)), color = "black", size = 1)+
  facet_grid(Level~cost_fn)+
  theme_few() +
    labs(title = "spearman additive cdf")+
    theme(aspect.ratio = 1)

gridExtra::grid.arrange(plot1, plot2)

```


# extra

```{r}
## create new targets, with list of clues as a new column

targets_and_clues = read_csv("data/exp3/cleaned.csv")  %>%
  select(word1, word2, Experiment, boardnames,wordpair,correctedClue)

clues_wide =targets_and_clues %>%
  group_by(wordpair) %>%
  summarise(clues = paste(unique(correctedClue), collapse = ','))

targets_and_clues = targets_and_clues %>% select(-correctedClue)%>% unique() %>%
  left_join(clues_wide)

write.csv(targets_and_clues, file = "data/exp3/revised_targets.csv", row.names = FALSE)

```

# board comparison

```{r}
  

clean_and_unite <- function(column) {
  column %>%
    mutate_all(~ str_remove_all(., "\\[|\\]|\""))
}

boards = readxl::read_excel("data/all_boards.xlsx") %>%
  clean_and_unite() %>%
  mutate(exp1 = str_split(gsub(",\\s*", " ", exp1), "\\s+"),
         exp2 = str_split(gsub(",\\s*", " ", exp2), "\\s+"),
         exp3 = str_split(gsub(",\\s*", " ", exp3), "\\s+")) %>%
  mutate(e1e3 = map2_lgl(exp1, exp3, ~ identical(sort(tolower(.x)), sort(tolower(.y)))),
         e1e2 = map2_lgl(exp1, exp2, ~ identical(sort(tolower(.x)), sort(tolower(.y)))),
         e2e3 = map2_lgl(exp2, exp3, ~ identical(sort(tolower(.x)), sort(tolower(.y)))))

e1e3_match = boards %>%
  filter(e1e3 == TRUE)



```


## accessibility

```{r}

clues = read_csv("data/exp3/cleaned.csv") 

cdfs = read_csv("data/exp3/model_output/cdfs_long.csv") %>%
  rename(correctedClue = "Word") %>%
  right_join(clues)



plot_data = cdfs %>% select(-Level) %>% mutate(wordpair = tolower(wordpair)) %>%
  left_join(wordpair_accuracy %>% select(wordpair, Level))%>%
  group_by(correctedClue,measure) %>%
  summarise(avg_cdf = mean(value, na.rm = TRUE))

low_values <- plot_data %>%
  filter(avg_cdf < 0.25 & measure > 8000) %>%
  filter(correctedClue %in% c("dopamine", "effect"))
  

high_values <- plot_data %>%
  filter(avg_cdf > 0.9 & measure < 130)%>%
  filter(correctedClue %in% c("flame", "cat"))

a_plot =  plot_data %>%
  ggplot(aes(x=measure, y = avg_cdf)) +
  geom_line(alpha = 0.15, aes(color = correctedClue))+
  scale_x_log10(limits = c(1, 10000)) +
  geom_text(data = high_values,
            aes(label = correctedClue, x = measure, y = avg_cdf),
            vjust = 1, hjust = 1, size = 3, color = "black") +
  geom_text(data = low_values,
            aes(label = correctedClue, x = measure, y = avg_cdf),
            vjust = 1, hjust = 1, size = 3, color = "black")+
    theme_few() +
    labs(x = "search budget", y = "cumulative probability of encountering clue", title = "accessibility") +
    theme(aspect.ratio = 1, legend.position = "none")



```
## informativity
```{r}
# informativity_paths = paste0(getwd(),"/data/exp3/model_output/informativity/")
# 
# informativity_dfs <- map_dfr(list.files(path = informativity_paths, pattern = "\\.csv$", full.names = TRUE), 
#                       ~read_csv(.x) %>% mutate(cost_fn = as.numeric(cost_fn))) 
# 
# informativity_dfs_main = informativity_dfs %>%
#   mutate( informativity= sub("cdf|freq", "", model),
#          cost_source = sub(".*(cdf|freq)", "\\1", model)) %>%
#   select(-c(cost_fn, costweight, alpha, model, cost_source)) %>%
#   distinct() %>%
#   filter(!is.na(prob)) %>%
#   filter(informativity != "no_prag") %>%
#   select(-Level) %>% mutate(wordpair = tolower(wordpair)) %>%
#   left_join(wordpair_accuracy %>% select(wordpair, Level))
# 
# 
# d_plot = informativity_dfs_main %>%
#   #filter(informativity == "additive" & distweight==0.04) %>%
#   filter(informativity == "RSA") %>% 
#   ggplot(aes(x = prob)) +
#   geom_histogram(binwidth = 0.01, fill = "aquamarine4", color = "darkgray")+
#   theme_few() +
#     labs(x = "clue informativity score", y = "density", title = "informativity") +
#     theme(aspect.ratio = 1, legend.position = "none")
# 
# gridExtra::grid.arrange(a_plot, d_plot, nrow = 1)
# 
# ggsave(here('analysis/plots/exp3_clue_metrics.pdf'), plot =gridExtra::grid.arrange(a_plot, d_plot, nrow = 1),
#        units = 'in', height = 4, width = 6)
# 
# ## was informativity related to listener accuracy?
# 
# listener_accuracy = informativity_dfs_main %>%
#   #filter(informativity == "additive" & distweight==0.04) %>% 
#   filter(informativity == "RSA") %>% 
#   select(wordpair,Clue1, correctedClue, prob) %>%
#   right_join(data_wide %>% rename(Clue1 = "clue"))
# 
# acc_model = glmer(data = listener_accuracy, accuracy ~ prob + (1|sona_id), family = binomial,
#                   control = glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# summary(acc_model)
# car::Anova(acc_model)

```

