---
title: "Search and pragmatics in Connector"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Imports

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggthemes)
library(tidyboot)
library(here)
library(jsonlite)
library(lme4)
library(broom.mixed)
setwd(here::here())
getwd()
library(ggrepel)
library(boot)
```

# behavioral data 

## import listener data

```{r}
listener = read_csv("../data/exp3/listener.csv") %>% 
  filter(typeoftrial %in% c("guess1", "guess2") & 
           accessibility %in% c("high", "low")) %>% 
  # excluding second attempt of 61440, identified by a different timestamp 
  filter(subject != 43110)

num_trials = listener %>%
  group_by(sona_id)%>%
  summarise(trials = n()) # should not exceed 480

## making data wide and calculating accuracy

data_wide = listener %>% 
  dplyr::select(sona_id, typeoftrial, wordpair, clue, accessibility, distinctiveness,
                            Board, Experiment, guess) %>%
  pivot_wider(names_from = "typeoftrial", values_from  = "guess") %>%
  mutate(accuracy = ifelse((str_detect(wordpair, tolower(guess1)) & 
                              str_detect(wordpair, tolower(guess2))), 1, 0))

subject_acc = data_wide %>%
  group_by(sona_id)%>%
  summarise_at(vars(accuracy), mean) %>%
  rename(mean_accuracy = accuracy)

num_trials = data_wide %>%
  group_by(sona_id)%>%
  summarise(trials = n())

exclude_subjects = unique(c((subject_acc %>% filter(mean_accuracy < .10))$sona_id,
                         (num_trials %>% filter(trials != 240))$sona_id))

## exclude <10% accuracy participants (pre-registered criterion)

data_wide = data_wide  %>% filter(!sona_id %in% exclude_subjects)%>%
  mutate(wordpair = tolower(gsub(" ", "", wordpair, fixed = TRUE)),
         clue = tolower(clue))

length(unique(data_wide$sona_id)) ## final N=31

# get mean accuracy per wordpair

wordpair_accuracy = data_wide %>% group_by(wordpair) %>%
  summarize(correct = mean(accuracy)) %>%
  mutate(Level = case_when(correct < .13 ~ 'Hard',
                           correct > .25 ~ 'Easy',
                           TRUE ~ 'Medium')) %>%
  mutate(Level = fct_relevel(Level, 'Easy', 'Medium', 'Hard'))

## histogram of wordpair_accuracy

wordpair_accuracy %>%
  ggplot(aes(x = correct*100, fill = Level)) +
    geom_histogram(bins = 30) +
    geom_vline(xintercept = c(14,25)) +
    labs(x = '% correct') +
    theme_few() +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave('plots/e3_difficulty_dist.pdf', units = 'in', width = 7, height = 4)



num_level = wordpair_accuracy %>% group_by(Level) %>% count() %>% 
  ungroup() %>%
  mutate(percent = n / sum(n))

## RTs

listener %>% 
  dplyr::select(sona_id, typeoftrial, wordpair, clue, rt) %>%
  pivot_wider(names_from = "typeoftrial", values_from  = "rt")%>%
  left_join(wordpair_accuracy) %>%
  mutate(guess1 = as.numeric(guess1), guess2 = as.numeric(guess2)) %>%
  rowwise()%>%
  mutate(mean_rt = (guess1+ guess2)/2)%>%
  group_by(Level) %>% tidyboot_mean(mean_rt, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean time to select word pairs (ms)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave('plots/exp3_generation_time.pdf', units = 'in', width = 4, height = 4)

## mean accuracy per clue 

clue_accuracy = data_wide %>% group_by(wordpair, clue) %>%
  summarize(correct = mean(accuracy))



```

## import speaker data

```{r}
raw_data = read_csv("../data/exp3/raw.csv") %>% 
  group_by(sona_id) %>%
  mutate(min_recorded_at = min(recorded_at)) %>%
  ungroup() %>%
  filter(recorded_at == min_recorded_at)%>%
  mutate(wordpair = gsub(' - ', '-', wordpair),
         response = as.numeric(response)) 

original_N = raw_data %>% pull(sona_id) %>% unique() %>% length()

e3_data = raw_data %>% 
  select(sona_id, subject, typeoftrial,wordpair, Clue1, correctedClue,  response, rt, condition, 
        accessibility, distinctiveness,  recorded_at)%>%
  filter(!is.na(wordpair) & accessibility != "prac") %>%
  rename(clue = "Clue1")

incomplete_IDs = e3_data %>% group_by(sona_id) %>% count() %>% filter(n < 240) %>% pull(sona_id)

mean_ratings_IDs = e3_data %>% group_by(sona_id) %>% 
  summarise(mean_rating = mean(response)) %>% filter(mean_rating < 1.5) %>% pull(sona_id)

final_data = e3_data %>% filter(!sona_id %in% c(incomplete_IDs, mean_ratings_IDs)) %>%
  mutate(wordpair = tolower(wordpair))
N = final_data %>% pull(sona_id) %>% unique() %>% length()
final_IDs = final_data %>% pull(sona_id) %>% unique()


num_ratings_per_pair = final_data %>% group_by(wordpair, sona_id) %>%
  count() 

ratings = final_data %>%
  group_by(wordpair, correctedClue) %>%
  # average all the rating scores, higher sum total means that clue was most preferred
  # across all participants
  summarise_at(vars(response), mean)%>%
  ungroup()%>%
  group_by(wordpair) %>%
  mutate(z_rating = as.numeric(scale(response)))

# ratings by level


final_data %>% left_join(wordpair_accuracy) %>%
  group_by(Level) %>% tidyboot_mean(response, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean rating (1-5)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

  
ggsave('plots/exp3_rating_plot.pdf', units = 'in', width = 4, height = 4)

# RTs by level

final_data %>% left_join(wordpair_accuracy) %>%
  group_by(Level) %>% tidyboot_mean(rt, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean time to rate clues (ms)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave('plots/exp3_rating_time.pdf', units = 'in', width = 4, height = 4)


```

## speaker-listener pattern

```{r}

original_ratings = final_data %>%
  group_by(wordpair, clue) %>%
  # average all the rating scores, higher sum total means that clue was most preferred
  # across all participants
  summarise_at(vars(response), mean)%>%
  ungroup()%>%
  group_by(wordpair) %>%
  mutate(z_rating = as.numeric(scale(response)))


clue_diagnosticity = final_data %>% select(wordpair, clue, correctedClue) %>% distinct() %>%
  left_join(clue_accuracy) %>%
  mutate(diagnosticity = ifelse(correct <= median(correct), "low", "high"))

speaker_listener = clue_accuracy %>% left_join(original_ratings) %>%
  left_join(clue_diagnosticity %>% select(-correct))

n_diag = speaker_listener %>% group_by(wordpair, diagnosticity) %>% count()

label_data= speaker_listener %>% 
  filter(wordpair %in% c("breeze-bubble", "weird-trauma", "tea-bean")) %>%
  mutate(x = paste0(wordpair, ":", clue))

speaker_listener %>%
  ggplot(aes(x = response, y = correct)) +
  geom_point(alpha = 0.05)+
  geom_smooth(method = "lm", color = "black", linewidth = 0.5)+
  geom_text_repel(
    data = label_data,
    aes(label = clue, color = wordpair), box.padding = 0.20, point.padding = 0.15,
    max.overlaps = Inf, segment.color = NA, fontface = "bold") +
  scale_y_continuous(limits = c(0,1))+
  scale_x_continuous(limits = c(1,5))+
  theme_few() +
  scale_color_manual(values = c('#60BD68', 'navy', '#CC253D'))+
    labs(x = "speaker ratings (1:low preference to 5: high preference)", y = "listener accuracy") +
    theme(aspect.ratio = 1)+
  theme(legend.position = c(0.2,0.75))

behavioral_model = lm(data = speaker_listener, correct ~ response)
summary(behavioral_model)
car::Anova(behavioral_model)

ggsave('plots/exp3_speaker_listener.pdf', units = 'in', width = 5, height = 5)


  
```




# model comparisons

## import model probs

```{r}
# grid_dfs = paste0(getwd(),"/../data/exp3/model_output/diagnostic/")
# 
# speaker_dfs <-map_dfr(list.files(path = grid_dfs, pattern = "\\.csv$", full.names = TRUE), ~read_csv(.x))
# 
# write.csv(speaker_dfs, file = paste0(getwd(),"/../data/exp3/model_output/all_speaker_dfs.csv"), row.names = FALSE)

speaker_dfs = read_csv("../data/exp3/model_output/all_speaker_dfs.csv")

model_plus_ratings = speaker_dfs %>% mutate(wordpair = tolower(wordpair)) %>%
  left_join(ratings) %>% 
  filter(!is.na(prob)) %>%
  select(wordpair, correctedClue, model, distweight, prob, z_rating, response) %>%
  distinct()%>%
  left_join(clue_diagnosticity)%>%
  mutate(model = ifelse(model == "additivecdf", "additive", "RSA"))

```
## correlations for speaker ratings
```{r}
# get correlation between each model and z-ratings

spearman = model_plus_ratings %>%
  # calculate correlation for each model and distweight 
  group_by(model,distweight) %>%
  # mutate(r = cor(prob, response, method = "spearman"))%>%
  # select(model, distweight, r) %>% distinct()
  mutate(r = psych::corr.test(prob, response, method = "spearman")$ci$r,
           ci_lower = psych::corr.test(prob, response, method = "spearman")$ci$lower,
           ci_upper = psych::corr.test(prob, response, method = "spearman")$ci$upper)%>%
  select(model, distweight, r, ci_lower, ci_upper) %>% distinct()

spearman %>%
  ggplot(aes(x = distweight, y = r, group = model, color = model)) +
  geom_line()+
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.1, color = NA) +
  geom_point(data = . %>% group_by(model) %>%
  filter(r == max(r)), size = 1.5)+
  theme_few() +
    scale_color_colorblind()+
    labs(y = "spearman correlation", x = "weight on distractors")+
    theme(aspect.ratio = 1)+
  theme(legend.position = c(0.2,0.3))

ggsave('plots/exp3_model_comparisons.pdf', units = 'in', height = 3, width = 7)

```

## diagnosticity

```{r}
diag_plot = model_plus_ratings %>%
  filter((model == "additive" & distweight %in% c( 0.24)) | 
           (model == "RSA" & distweight %in% c(0.58))) %>%
  mutate(`model predictions` = scales::rescale(prob, to = c(0,1)),
         `human ratings` = scales::rescale(response, to = c(0,1))) %>%
  pivot_longer(names_to = "metric", cols = c(`model predictions`, `human ratings`)) %>%
  group_by(diagnosticity, metric) %>%
  tidyboot_mean(value, nboot = 1000, na.rm = T)  %>%
  mutate(metric = fct_relevel(metric, "human ratings", "model predictions"))

human = diag_plot %>% 
  filter(metric == "human ratings") %>%
  ggplot(aes(x = diagnosticity, y = empirical_stat, group = diagnosticity, fill = diagnosticity)) +
  geom_bar(stat = 'identity', position = "dodge") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, position =  position_dodge(0.9)) +
    labs(y = 'normalized ratings', x= "") +
    facet_wrap(~metric)+
    theme_few() +
    theme(aspect.ratio = 1, legend.position = "none") +
    scale_fill_manual(values = c('darkslategray4',  '#CC253D'))

model = diag_plot %>% 
  filter(metric == "model predictions") %>%
  ggplot(aes(x = diagnosticity, y = empirical_stat, group = diagnosticity, fill = diagnosticity)) +
  geom_bar(stat = 'identity', position = "dodge") +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, position =  position_dodge(0.9)) +
  labs(y = 'normalized predictions', x= "") +
  facet_wrap(~metric)+
    theme_few() +
    theme(aspect.ratio = 1, legend.position = c(0.75, 0.8)) +
    scale_fill_manual(values = c('darkslategray4',  '#CC253D'))



ggsave('plots/exp3_model_diag.pdf', units = 'in',
       plot = gridExtra::grid.arrange(human, model, nrow = 1), height = 4, width = 8)

```
## examples
```{r}
best_model = model_plus_ratings %>%
  filter((model == "additive" & distweight %in% c( 0.24)) | 
           (model == "RSA" & distweight %in% c(0.58))) %>%
  mutate(`model predictions` = scales::rescale(prob, to = c(0,1)),
         `human ratings` = scales::rescale(response, to = c(0,1)))%>%
  filter(wordpair %in% c("lion-tiger", "weird-trauma", "breeze-bubble", "cave-knight")) %>%
  select(wordpair, clue, model, `human ratings`, `model predictions`)%>%
  arrange(wordpair)


```


# extra

```{r}
## create new targets, with list of clues as a new column

targets_and_clues = read_csv("data/exp3/cleaned.csv")  %>%
  select(word1, word2, Experiment, boardnames,wordpair,correctedClue)

clues_wide =targets_and_clues %>%
  group_by(wordpair) %>%
  summarise(clues = paste(unique(correctedClue), collapse = ','))

targets_and_clues = targets_and_clues %>% select(-correctedClue)%>% unique() %>%
  left_join(clues_wide)

write.csv(targets_and_clues, file = "data/exp3/revised_targets.csv", row.names = FALSE)

```

## board comparison

```{r}
  

clean_and_unite <- function(column) {
  column %>%
    mutate_all(~ str_remove_all(., "\\[|\\]|\""))
}

boards = readxl::read_excel("data/all_boards.xlsx") %>%
  clean_and_unite() %>%
  mutate(exp1 = str_split(gsub(",\\s*", " ", exp1), "\\s+"),
         exp2 = str_split(gsub(",\\s*", " ", exp2), "\\s+"),
         exp3 = str_split(gsub(",\\s*", " ", exp3), "\\s+")) %>%
  mutate(e1e3 = map2_lgl(exp1, exp3, ~ identical(sort(tolower(.x)), sort(tolower(.y)))),
         e1e2 = map2_lgl(exp1, exp2, ~ identical(sort(tolower(.x)), sort(tolower(.y)))),
         e2e3 = map2_lgl(exp2, exp3, ~ identical(sort(tolower(.x)), sort(tolower(.y)))))

e1e3_match = boards %>%
  filter(e1e3 == TRUE)



```


## accessibility

```{r}

clues = read_csv("data/exp3/cleaned.csv") 

cdfs = read_csv("data/exp3/model_output/cdfs_long.csv") %>%
  rename(correctedClue = "Word") %>%
  right_join(clues)



plot_data = cdfs %>% select(-Level) %>% mutate(wordpair = tolower(wordpair)) %>%
  left_join(wordpair_accuracy %>% select(wordpair, Level))%>%
  group_by(correctedClue,measure) %>%
  summarise(avg_cdf = mean(value, na.rm = TRUE))

low_values <- plot_data %>%
  filter(avg_cdf < 0.25 & measure > 8000) %>%
  filter(correctedClue %in% c("dopamine", "effect"))
  

high_values <- plot_data %>%
  filter(avg_cdf > 0.9 & measure < 130)%>%
  filter(correctedClue %in% c("flame", "cat"))

a_plot =  plot_data %>%
  ggplot(aes(x=measure, y = avg_cdf)) +
  geom_line(alpha = 0.15, aes(color = correctedClue))+
  scale_x_log10(limits = c(1, 10000)) +
  geom_text(data = high_values,
            aes(label = correctedClue, x = measure, y = avg_cdf),
            vjust = 1, hjust = 1, size = 3, color = "black") +
  geom_text(data = low_values,
            aes(label = correctedClue, x = measure, y = avg_cdf),
            vjust = 1, hjust = 1, size = 3, color = "black")+
    theme_few() +
    labs(x = "search budget", y = "cumulative probability of encountering clue", title = "accessibility") +
    theme(aspect.ratio = 1, legend.position = "none")



```
