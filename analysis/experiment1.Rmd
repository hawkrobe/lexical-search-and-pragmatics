---
title: "R Notebook"
output: html_notebook
---

# Imports

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggthemes)
library(tidyboot)
library(here)
library(jsonlite)

d_exp1 <- read_csv(here("data/exp1/cleaned.csv")) %>%
  mutate(Level = fct_collapse(Level, Hard = c("Medium", "Hard")))

```

# 0. blended model

```{r}
logsumexp <- function(x) {
  y <- max(x)
  y + log(sum(exp(x - y)))
}

softmax <- function(x) {
  exp(x - logsumexp(x))
}

blended_raw <- read_csv(here("data/exp1/model_output/blended.csv")) %>%
  select(-n) %>%
  filter(!is.na(cost_weight)) %>%
  rename(correctedClue = Word) %>%
  group_by(wordpair) %>%
  complete(correctedClue, cost_weight, step, fill = list(cdf = 0))
```

```{r}
blended <- blended_raw %>%
  group_by(wordpair) %>%
  mutate(prob = softmax(10 * cdf)) %>%
  ungroup() %>%
  right_join(d_exp1, relationship = "many-to-many") %>%
  group_by(wordpair, cost_weight, step) %>%
  summarize(loglik = sum(log(prob), na.rm = TRUE))

blended %>%
  ggplot(aes(x = as.numeric(step), y = loglik,
             color = cost_weight, group = cost_weight,
             linetype = cost_weight %in% c(0,1))) +
    geom_line() +
    facet_wrap(wordpair ~ ., scales = 'free') +
    scale_x_log10() +
    ylim(-33000, -22000) +
    theme_few() +
    labs(x = "search budget") +
    theme(aspect.ratio = 1)
```

# 1. speaker selections

```{r}
d.exp1 <- read_csv(here("data/exp1/cleaned.csv"))

likelihoods <- read_csv(here("data/exp1/model_output/speaker_df.csv")) %>%
  select(model, wordpair, alpha, costweight, distweight, correctedClue, Level, cost_fn, prob) %>%
  mutate(Level = fct_relevel(Level, 'Easy', 'Medium', 'Hard')) 
```

```{r}
likelihoods %>%
  group_by(cost_fn, model, alpha, distweight, costweight, Level) %>%
  summarize(loglik = sum(log(prob), na.rm = T)) %>%
  group_by(model, Level, cost_fn) %>%
  filter(loglik == max(loglik)) %>%
  ggplot(aes(x = as.numeric(cost_fn), y = loglik, color = Level)) +
    geom_line(stat = 'identity', data = . %>% filter(model == 'additivecdf'), alpha = 0.5) +
    geom_hline(aes(yintercept = loglik, color = Level), linetype = 'dashed', data = . %>% filter(model == 'additivefreq')) +
    geom_line(linetype = 'dotted', data = . %>% filter(model == 'no_pragcdf')) +
    geom_point(data = . %>% group_by(Level) %>% filter(loglik == max(loglik))) +
    facet_wrap(~ Level, scales = 'free') +
    scale_x_log10(limits = c(1, 10000)) +
    scale_color_manual(values = c('#60BD68', '#D8CF23', '#CC253D')) +
    theme_few() +
    labs(x = "search budget") +
    theme(aspect.ratio = 1, legend.position = 'none')

ggsave(here('analysis/plots/exp1_modelcomparison.pdf'), units = 'in', height = 3, width = 7)
```

Broken out by difficulty

```{r}
library(xtable)
likelihoods %>%
  group_by(Level, model, cost_fn, alpha, costweight, distweight) %>%
  summarize(loglik = sum(log(prob), na.rm = T)) %>%
  group_by(model, Level) %>%
  filter(loglik == max(loglik)) %>%
  arrange(Level, -loglik) %>%
  xtable()
  
```



```{r}
d.toplot <- likelihoods %>%
  filter(costweight %in% c(0, .01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1)) %>%
  group_by(cost_fn, model, alpha, distweight, costweight, Level) %>%
  summarize(loglik = sum(log(prob), na.rm = T)) %>%
  group_by(Level, model, costweight) %>%
  filter(loglik == max(loglik)) 

d.toplot %>%
  ggplot(aes(x = costweight, y = loglik, linetype = model, color = Level)) +
    geom_line() +
    facet_grid( ~ Level, scales = 'free') +
    scale_x_log10() +
    geom_point(data = . %>% group_by(Level) %>% filter(loglik == max(loglik))) +
    scale_color_manual(values = c('#60BD68', '#D8CF23', '#CC253D')) +
    scale_linetype_manual(values = c('solid', 'dashed', 'dotted')) +
    theme_few() +
    labs(x = "cost weight") +
    theme(aspect.ratio = 1, legend.position = 'top')

ggsave(here('analysis/plots/exp1_costscale.pdf'), units = 'in', height = 3, width = 7)
```


```{r}
likelihoods %>%
  filter(costweight %in% c(0, .01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1)) %>%
  group_by(cost_fn, model, alpha, distweight, costweight, Level) %>%
  summarize(loglik = sum(log(prob), na.rm = T)) %>%
  rename(budget = cost_fn) %>% 
  group_by(Level, model, budget, costweight) %>%
  mutate(loglik = ifelse(loglik < -5000, -5000, loglik)) %>%
  filter(loglik == max(loglik)) %>%
  ungroup() %>%
  complete(Level, model, budget, costweight, fill = list(loglik = NA)) %>%
  group_by(Level, model, costweight) %>%
  mutate(loglik = ifelse(is.na(loglik), mean(loglik, na.rm = T), loglik)) %>%
  ggplot(aes(x = costweight, y = as.numeric(budget), fill = loglik)) +
    geom_tile(stat = 'identity', height=.34, width=.33) +
    geom_tile(color = 'black', stat = 'identity', height=.34, width=.33, size = 1.1,
              data = . %>% group_by(Level, model) %>% filter(loglik == max(loglik))) +
    facet_grid(Level ~ model) +
    scale_x_log10() +
    scale_y_log10() +
    scale_fill_gradient2(midpoint = -4250) +
    theme_few() +
    labs(y = "search budget", "cost weight") +
    theme(aspect.ratio = 1)

ggsave(here("analysis/plots/exp1_heatmap.pdf"), units = 'in', width = 6, height = 5)
```

# Reformat

```{r}
complete_df <- read_csv(here('data/exp1/model_input/vocab.csv')) %>%
  left_join(read_csv(here('data/exp1/model_output/ranks.csv'))) %>%
  mutate(single = (w1_index_walk + w2_index_walk)/2) %>%
  select(-`...1`, -index, -Occurrences,-Length) %>%
  gather(measure, value, -Word, -wordpair) %>%
  complete(Word, wordpair, measure, fill = list(value = 0)) %>%
  filter(!is.na(step), !is.na(wordpair))

read_csv(here('data/exp1/model_input/vocab.csv')) %>%
  left_join(complete_df) %>%
  select(Word,wordpair,measure,value) %>%
  write_csv(here('data/exp1/model_output/freqs_long.csv'))
```