---
title: "R Notebook"
output: html_notebook
---

# Imports

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggthemes)
library(tidyboot)
library(here)
library(jsonlite)
```

# 1. speaker selections

```{r}
d.exp2 <- read_csv(here("data/exp2/cleaned.csv"))

here("data/exp2/model_output/speaker_df.csv") |> 
  read_csv() |>
  select(wordpair, alpha, costweight, correctedClue, Level,cost,prag_speaker_probs,prag_speaker_rank) %>%
  mutate(prob = log(prag_speaker_probs)) %>%
  group_by(cost, alpha, costweight, Level) %>%
  summarize(rank = mean(prag_speaker_rank, na.rm = T),
            loglik = sum(prob, na.rm = T)) %>%
  group_by(cost, Level, costweight) %>%
  filter(loglik == max(loglik)) %>%
  ggplot(aes(x = costweight, y = rank, color = alpha)) +
    geom_line() +
    facet_grid(Level ~ cost) +
    scale_x_log10() +
    theme_few()

```

## overall patterns

```{r}
e2_search = search %>%
    mutate(model= "walk-only", alpha = "walk-only",
           wordpair = gsub('\\s+', '', wordpair))%>%
  select(wordpair, boardnames, budget, clue, model, alpha, type, value )

max(e2_search$value)

e2_nonRSA = read_csv("nonRSAprobs.csv") %>% mutate(model = "nonRSA", alpha = as.character(alpha)) 
e2_RSA = read_csv("RSAprobs.csv") %>% mutate(model = "RSA", alpha = "RSA")

e2_nonRSA_RSA = rbind(e2_RSA, e2_nonRSA) %>%
  rename(union = clue_probs_union, intersection = clue_probs_intersection)%>%
  pivot_longer(names_to = "type", cols = union:intersection)

e2_combined_models = rbind(e2_search, e2_nonRSA_RSA) %>%
  left_join(e2_clues) %>%
  mutate(LL = log(value)*clueCount,
         budget = as.numeric(gsub("[^0-9.-]", "", budget)))

# histogram
e2_combined_models %>%
  ggplot(aes(x = LL, group = model, fill = model)) +
  geom_histogram(binwidth = 50) + theme_few()

e2_sumLL = e2_combined_models %>% 
  group_by(alpha, budget, type)%>%
  summarize_at(vars(LL), sum)
  
e2_plot = e2_sumLL %>%
  ggplot(aes(x = budget, y = LL, color = alpha, group = alpha)) +
  geom_point(size = 2)+
  geom_line()+
  facet_wrap(~type)+
    labs(y = 'log likelihood', title = "E2: model likelihoods") +
    theme_few() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
         aspect.ratio = 1.5) 

ggsave("../../analysis/plots/exp2_plot.pdf", e2_plot)

```

## item analysis

```{r}
e2_behavioral = e2_clues %>% select(wordpair, clue, clueCount) %>%
  group_by(wordpair) %>%
  slice_max(clueCount) %>% group_by(wordpair) %>% slice(1) %>%
  mutate(model = "behavioral") %>% select(wordpair, model, clue)

e2_top_predictions = e2_combined_models %>%
  group_by(wordpair, model) %>%
  slice_max(value)%>%
  group_by(wordpair, model) %>%
  slice(1) %>% select(wordpair, model, clue) %>%
  rbind(e2_behavioral)%>%
  pivot_wider(names_from = model, values_from = clue)

e2_top_predictions %>%
  mutate(walk_score = ifelse(`walk-only` == behavioral, 1,0),
         nonRSA_score = ifelse(nonRSA == behavioral, 1, 0),
         RSA_score = ifelse(RSA == behavioral, 1, 0))  %>%
  pivot_longer(names_to = "score", cols=c(walk_score, nonRSA_score, RSA_score))%>%
  group_by(score)%>%
  summarise_at(vars(value), mean)

## correlation: RSA correlates best with clueCounts
e2_combined_models %>% left_join(targets)%>%
  group_by(model) %>%
  summarize(cor(value, clueCount))
```

## Compute costs for the whole vocab

```{r}
pairs <- d.exp2 %>% pull(wordpair) %>% unique()

getWalks <- function(pair) {
  paste0('data/exp2/model_output/', pair, '-walks.json', collapse = '') %>%
    here() %>%
    fromJSON() %>% 
    as_tibble() %>%
    mutate(step = row_number()) %>%
    gather(walk, Word, -step) %>%
    mutate(walk = gsub('walk-', '', walk),
           wordpair = pair) %>% 
    group_by(walk, Word, wordpair) %>%
    filter(step == first(step)) %>%
    group_by(step, Word, wordpair) %>%
    tally() %>%
    ungroup() %>%
    group_by(wordpair) %>%
    complete(Word, step = 2**seq(13), fill = list(n=0)) %>%
    group_by(Word, wordpair) %>%
    arrange(step) %>%
    mutate(cdf = cumsum(n)/2000) %>%
    filter(step %in% 2**seq(13)) %>%
    write_csv(here(paste0('data/exp2/model_output/', pair, '-cdf.csv',collapse = '')))
}

library(furrr)
library(progressr)

plan(multisession, workers = 8)
cdfs <- with_progress({
    p <- progressor(steps = length(pairs))
    future_walk(pairs, ~{p(); getWalks(.x)}) 
})
```
# Reformat

```{r}
complete_df <- read_csv(here('data/exp2/model_input/vocab.csv')) %>%
  left_join(read_csv(here('data/exp2/model_output/cdfs.csv'))) %>%
  select(Word,wordpair,step,cdf) %>%
  complete(Word, wordpair, step, fill = list(cdf = 0)) %>%
  filter(!is.na(step), !is.na(wordpair))

read_csv(here('data/exp2/model_input/vocab.csv')) %>%
  left_join(complete_df) %>%
  select(Word,wordpair,step,cdf) %>%
  write_csv(here('data/exp2/model_output/cdfs_long.csv'))
```