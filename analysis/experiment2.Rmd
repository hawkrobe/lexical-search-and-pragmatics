---
title: "Experiment 2 (Targeted Endorsements)"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

# Imports

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggthemes)
library(tidyboot)
library(here)
library(jsonlite)
library(lme4)
library(broom.mixed)
setwd(here::here())
getwd()
library(ggrepel)
library(boot)
```

# behavioral data 

## import listener data

```{r}
listener = read_csv("../data/exp2/listener.csv") %>% 
  filter(typeoftrial %in% c("guess1", "guess2") & 
           accessibility %in% c("high", "low")) %>% 
  # excluding second attempt of 61440, identified by a different timestamp 
  filter(subject != 43110)

num_trials = listener %>%
  group_by(sona_id)%>%
  summarise(trials = n()) # should not exceed 480

## making data wide and calculating accuracy

data_wide = listener %>% 
  dplyr::select(sona_id, typeoftrial, wordpair, clue, accessibility, distinctiveness,
                            Board, Experiment, guess) %>%
  pivot_wider(names_from = "typeoftrial", values_from  = "guess") %>%
  mutate(accuracy = ifelse((str_detect(wordpair, tolower(guess1)) & 
                              str_detect(wordpair, tolower(guess2))), 1, 0))

subject_acc = data_wide %>%
  group_by(sona_id)%>%
  summarise_at(vars(accuracy), mean) %>%
  rename(mean_accuracy = accuracy)

num_trials = data_wide %>%
  group_by(sona_id)%>%
  summarise(trials = n())

exclude_subjects = unique(c((subject_acc %>% filter(mean_accuracy < .10))$sona_id,
                         (num_trials %>% filter(trials != 240))$sona_id))

## exclude <10% accuracy participants (pre-registered criterion)

data_wide = data_wide  %>% filter(!sona_id %in% exclude_subjects)%>%
  mutate(wordpair = tolower(gsub(" ", "", wordpair, fixed = TRUE)),
         clue = tolower(clue))

length(unique(data_wide$sona_id)) ## final N=31

# get mean accuracy per wordpair

wordpair_accuracy = data_wide %>% group_by(wordpair) %>%
  summarize(correct = mean(accuracy)) %>%
  mutate(listener_tertile = ntile(correct, 3)) %>%
  mutate(Level = ifelse(listener_tertile == 3, "Easy", 
                        ifelse(listener_tertile == 2, "Medium", "Hard"))) %>%
  # mutate(Level = case_when(correct < .13 ~ 'Hard',
  #                          correct > .25 ~ 'Easy',
  #                          TRUE ~ 'Medium')) %>%
  mutate(Level = fct_relevel(Level, 'Easy', 'Medium', 'Hard'))

## histogram of wordpair_accuracy

wordpair_accuracy %>%
  ggplot(aes(x = correct*100, fill = Level)) +
    geom_histogram(bins = 30) +
    labs(x = '% correct') +
    theme_few() +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))+
  theme(legend.position = c(0.8,0.8))

ggsave('plots/exp2_difficulty_dist.pdf', units = 'in', width = 7, height = 4)



num_level = wordpair_accuracy %>% group_by(Level) %>% count() %>% 
  ungroup() %>%
  mutate(percent = n / sum(n))

## RTs

listener %>% 
  dplyr::select(sona_id, typeoftrial, wordpair, clue, rt) %>%
  pivot_wider(names_from = "typeoftrial", values_from  = "rt")%>%
  left_join(wordpair_accuracy) %>%
  mutate(guess1 = as.numeric(guess1), guess2 = as.numeric(guess2)) %>%
  rowwise()%>%
  mutate(mean_rt = (guess1+ guess2)/2)%>%
  group_by(Level) %>% tidyboot_mean(mean_rt, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean time to select word pairs (ms)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave('plots/exp2_generation_time.pdf', units = 'in', width = 4, height = 4)

## mean accuracy per clue 

clue_accuracy = data_wide %>% group_by(wordpair, clue) %>%
  summarize(correct = mean(accuracy))



```

## import speaker data

```{r}
raw_data = read_csv("../data/exp2/raw.csv") %>% 
  group_by(sona_id) %>%
  mutate(min_recorded_at = min(recorded_at)) %>%
  ungroup() %>%
  filter(recorded_at == min_recorded_at)%>%
  mutate(wordpair = gsub(' - ', '-', wordpair),
         response = as.numeric(response)) 

original_N = raw_data %>% pull(sona_id) %>% unique() %>% length()

e2_data = raw_data %>% 
  select(sona_id, subject, typeoftrial,wordpair, Clue1, correctedClue,  response, rt, condition, 
        accessibility, distinctiveness,  recorded_at)%>%
  filter(!is.na(wordpair) & accessibility != "prac") %>%
  rename(clue = "Clue1")

incomplete_IDs = e2_data %>% group_by(sona_id) %>% count() %>% filter(n < 240) %>% pull(sona_id)

mean_ratings_IDs = e2_data %>% group_by(sona_id) %>% 
  summarise(mean_rating = mean(response)) %>% filter(mean_rating < 1.5) %>% pull(sona_id)

final_data = e2_data %>% filter(!sona_id %in% c(incomplete_IDs, mean_ratings_IDs)) %>%
  mutate(wordpair = tolower(wordpair))
N = final_data %>% pull(sona_id) %>% unique() %>% length()
final_IDs = final_data %>% pull(sona_id) %>% unique()


num_ratings_per_pair = final_data %>% group_by(wordpair, sona_id) %>%
  count() 

ratings = final_data %>%
  group_by(wordpair, correctedClue) %>%
  # average all the rating scores, higher sum total means that clue was most preferred
  # across all participants
  summarise_at(vars(response), mean)%>%
  ungroup()%>%
  group_by(wordpair) %>%
  mutate(z_rating = as.numeric(scale(response)))

#write.csv(ratings, "../data/exp2/ratings.csv", row.names = FALSE)

# ratings by level


final_data %>% left_join(wordpair_accuracy) %>%
  group_by(Level) %>% tidyboot_mean(response, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean rating (1-5)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

  
ggsave('plots/exp2_rating_plot.pdf', units = 'in', width = 4, height = 4)

# RTs by level

final_data %>% left_join(wordpair_accuracy) %>%
  group_by(Level) %>% tidyboot_mean(rt, nboot = 1000, na.rm = T) %>% 
  ggplot(aes(x = Level, y = empirical_stat, fill = Level)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    labs(y = 'mean time to rate clues (ms)') +
    theme_few() +
    scale_fill_few() +
    theme(aspect.ratio = 1, legend.position = 'none') +
    scale_fill_manual(values = c('#60BD68', '#D8CF23', '#CC253D'))

ggsave('plots/exp2_rating_time.pdf', units = 'in', width = 4, height = 4)


```

## speaker-listener pattern

```{r}

original_ratings = final_data %>%
  group_by(wordpair, clue) %>%
  # average all the rating scores, higher sum total means that clue was most preferred
  # across all participants
  summarise_at(vars(response), mean)%>%
  ungroup()%>%
  group_by(wordpair) %>%
  mutate(z_rating = as.numeric(scale(response)))

speaker_listener = clue_accuracy %>% left_join(original_ratings)

label_data= speaker_listener %>% 
  filter(wordpair %in% c("weird-trauma", "tea-bean",
                         "lion-tiger")) %>%
  mutate(x = paste0(wordpair, ":", clue))

speaker_listener %>%
  ggplot(aes(x = response, y = correct)) +
  geom_point(alpha = 0.1)+
  geom_smooth(method = "lm", color = "black", linewidth = 0.3)+
  geom_text_repel(
    data = label_data,
    aes(label = clue, 
        color = wordpair), box.padding = 0.20, point.padding = 0.15,
    max.overlaps = Inf, segment.color = NA, fontface = "bold", size = 5) +
  scale_y_continuous(limits = c(-0.05,1))+
  scale_x_continuous(limits = c(1,5))+
  theme_few() +
  scale_color_manual(values = c('#60BD68', 'darkgoldenrod3', '#CC253D'))+
    labs(x = "speaker ratings (1:low preference to 5: high preference)", y = "listener accuracy") +
    theme(aspect.ratio = 1)+
  theme(legend.position = c(0.2,0.75),
        legend.key.size = unit(1, 'cm'), 
        legend.title = element_text(size=15),
        legend.text = element_text(size=12))

behavioral_model = lm(data = speaker_listener, correct ~ response)
summary(behavioral_model)
car::Anova(behavioral_model)

ggsave('plots/exp2_speaker_listener.pdf', units = 'in', width = 5, height = 5)
```




# model comparisons

## import model probs

```{r}

e2_speaker_df = read_csv("../data/exp2/model_output/speaker_df.csv")

model_plus_ratings = e2_speaker_df %>% 
  mutate(wordpair = tolower(wordpair)) %>%
  select(-Level) %>%
  left_join(wordpair_accuracy) %>%
  left_join(ratings) %>% 
  # exclude words that are not in vocab
  filter(!is.na(prob))
```
## correlations for speaker ratings
```{r}
# get correlation between each model and z-ratings

spearman = model_plus_ratings %>%
  mutate(type = ifelse(costweight == 1, "no pragmatics", 
          ifelse(costweight == 0, "no search", "search + pragmatics"))) %>%
  ungroup() %>%
  group_by(type, Level, model, alpha, cost_fn, costweight) %>%
  summarise(r = psych::corr.test(prob, response, method = "spearman")$ci$r,
           ci_lower = psych::corr.test(prob, response, method = "spearman")$ci$lower,
           ci_upper = psych::corr.test(prob, response, method = "spearman")$ci$upper)


best_corr = spearman %>%
  ungroup() %>%
  group_by(Level, type, model, costweight) %>%
  slice(which.max(r)) 

best_corr %>%
  filter(model %in% c("RSAcdf", "RSAfreq"))%>%
  ggplot(aes(x = as.numeric(costweight), y = r)) +
  geom_line(stat = 'identity', data = . %>% filter(model == 'RSAcdf'),
            aes(group = type, color = type))+
  geom_line(stat = 'identity', data = . %>% filter(model == 'RSAfreq'),
             linetype = 'dashed', 
            aes(group = type, color = type))+
  geom_hline(aes(yintercept = r, color = type), 
             linetype = 'dashed', 
             data = . %>% filter(model == 'RSAfreq' & type == "no search")) +
  geom_hline(aes(yintercept = r, color = type), 
             linetype = 'dashed', 
             data = . %>% filter(model == 'RSAfreq' & type == "no pragmatics")) +
  geom_hline(aes(yintercept = r, color = type), 
             linetype = 'dotted', 
             data = . %>% filter(model == 'RSAcdf' & type == "no pragmatics")) +
  geom_point(data = . %>% group_by(Level) %>% filter(r == max(r)), 
             color = "black") +
  facet_grid(~Level) +
  scale_color_manual(values = c('#60BD68', '#D8CF23', '#CC253D')) +
  theme_few() +
  labs(y = "spearman's r", x= "weight on accessibility") +
  theme(aspect.ratio = 1,
        legend.position = c(0.85,0.3),
        legend.key.size = unit(0.3, "cm"))
  
ggsave('plots/exp2_model_comparisons.pdf', units = 'in', height = 3, width = 7)

```

## no cost model

```{r}
best_corr %>% filter(type == "no search")
```

## examples

```{r}
level_bestfit = spearman %>% ungroup() %>%
  group_by(Level) %>% 
  slice(which.max(r))

# identify pairs where boards changed

critical_pairs_raw =c("LION-TIGER", "TIGER-LION", 
                  "SNAKE-ASH", "ASH-SNAKE", 
                  "HAND-BIRTH", "BIRTH-HAND",
                  "QUICK-GLOW", "GLOW-QUICK",
                  "TREE-OAK","OAK-TREE",
                  "CAVE-KNIGHT", "KNIGHT-CAVE",
                  "HOLY-KIND", "KIND-HOLY",
                  "RUDE-REGRET", "REGRET-RUDE",
                  "TEETH-GUMS", "GUMS-TEETH",
                  "JUMP-LEAP", "LEAP-JUMP",
                  "TRAVEL-ANKLE", "ANKLE-TRAVEL",
                 "DREAM-BET", "BET-DREAM", 
                 "ELM-ROCK", "ROCK-ELM",
                 "CRUST-BOOT", "BOOT-CRUST",
                 "SIT-STAND", "STAND-SIT",
                "GIANT-SUBTLE", "SUBTLE-GIANT",
                "ARMY-DRUM", "DRUM-ARMY",
                "HAPPY-SAD", "SAD-HAPPY")

critical_pairs = as.data.frame(critical_pairs_raw) %>% 
  rename(wordpair = critical_pairs) %>% mutate(wordpair = tolower(wordpair))

# identify the clues that were rated for each of these

critical_clues = ratings %>% filter(wordpair %in% critical_pairs$wordpair) %>%
  select(wordpair, correctedClue) %>% 
  mutate(correctedClue = ifelse(correctedClue == "pokemon", "Pokemon", correctedClue))%>%
  group_by(wordpair) %>%
  summarize(collapsed_clues = str_c(correctedClue, collapse = ", "))

exp2_params = critical_pairs %>%
  left_join(wordpair_accuracy %>% select(wordpair, Level))%>%
  filter(!is.na(Level)) %>%
  left_join(level_bestfit %>% select(Level, alpha, cost_fn, costweight))  %>%
  left_join(critical_clues)

# write.csv(exp2_params,
#           file = "../data/exp2/model_input/example_params.csv", 
#           row.names = FALSE)

# obtain model probabilities

exp1vsexp2 = rbind(read_csv("../data/exp1/model_output/multiple_examples.csv") %>%
                     mutate(exp = "E1"), 
                   read_csv("../data/exp2/model_output/multiple_examples.csv") %>%
                     mutate(exp = "E2")) %>%
  rename(correctedClue = clue)

# get experiment 1 data
exp1_counts = read_csv("../data/exp1/cleaned.csv")%>%
  select(wordpair, correctedClue, boardnames) %>%
  mutate(wordpair = ifelse(wordpair == "ASH-SNAKE", "SNAKE-ASH", 
                           ifelse(wordpair == "BET-DREAM", "DREAM-BET", wordpair))) %>%
  mutate(correctedClue = ifelse(correctedClue == "animals", "animal",
                                ifelse(correctedClue == "cats", "cat",
                                       ifelse(correctedClue == "bears", "bear",
                                  ifelse(correctedClue == "mammals", "mammal", correctedClue))))) %>%
  group_by(wordpair, correctedClue) %>% count() %>% mutate(exp = "E1")

exp1vsexp2 = exp1vsexp2 %>%
  left_join(exp1_counts) %>%
  left_join(ratings %>% mutate(exp = "E2") %>%
              select(wordpair, correctedClue, response, exp)) %>%
  group_by(wordpair, exp) %>%
  mutate(speaker_rank = ifelse(exp == "E1", rank(n), rank(response)),
         model_rank = rank(utility))

```

### lion-tiger
```{r}
exp1vsexp2 %>%
  mutate(exp = as.factor(exp)) %>%
  mutate(exp = fct_recode(as.factor(exp), `E1 (utterances)` = "E1", `E2 (ratings)` = "E2")) %>%
  filter(wordpair %in% c("lion-tiger")) %>%
  rename(`speaker ranks` = "speaker_rank", `model ranks` = "model_rank")%>%
  pivot_longer(names_to = "type", cols = `model ranks`:`speaker ranks` ) %>%
  mutate(type = as.factor(type),
         type = fct_relevel(type, "speaker ranks", "model ranks")) %>%
  ggplot(aes(x = exp, y = value, group =correctedClue , fill = correctedClue)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = correctedClue), 
            position = position_dodge(width = 0.9), 
            vjust = 0.5, 
            hjust = 1.1,
            angle = 90, 
            color = "white", 
            size = rel(4)) +
  facet_wrap(~type) + 
  scale_fill_calc()+
  theme_few() +
  labs(x = "", y = "ranks")+
  theme(aspect.ratio = 1, 
        legend.position =  "none",
        axis.text.x = element_text(size = rel(1.5)),
        strip.text.x = element_text(size = rel(1.5)))
ggsave('plots/exp2_lion_tiger_ranks.pdf', units = 'in', height = 4, width = 8)

```

### other pairs

```{r}

exp1vsexp2 %>%
  mutate(exp = as.factor(exp)) %>%
  mutate(exp = fct_recode(as.factor(exp), `E1 (utterances)` = "E1", `E2 (ratings)` = "E2")) %>%
  rename(`speaker ranks` = "speaker_rank")%>%
  ggplot(aes(x = exp, y = `speaker ranks`, group =correctedClue , fill = correctedClue)) +
  geom_col(position = "dodge", color = "black") +
  facet_wrap(~wordpair, nrow = 6) + 
  geom_text(aes(label = correctedClue), 
            position = position_dodge(width = 0.9), 
            vjust = 0.5, 
            hjust = -0.2,
            angle = 90, 
            color = "black", 
            size = rel(3.5)) +
  theme_few() +
  labs(x = "", y = "speaker ranks")+
  theme(
        legend.position =  "none",
        axis.text.x = element_text(size = rel(1.5)),
        strip.text = element_text(size = 12, face = "bold", color = "white"),
    strip.background = element_rect(color = "black", fill = "darkgray")
  )

ggsave('plots/exp2_example.pdf',units = 'in', height = 13, width = 10)

```

# demographics

## speaker

```{r}
speaker_data = read_csv("../data/exp2/raw.csv") %>%
  filter(sona_id %in% raw_data$sona_id)%>%
  filter(typeoftrial %in% c("demo", "english")) %>% 
  select(sona_id, response) %>% filter(response != 0)

parsed_speaker = speaker_data %>%
  mutate(response = map(response, ~fromJSON(.x))) %>% 
  unnest_wider(response) %>%
  mutate(Race = map(Race, ~if (is.null(.x)) NA else .x)) %>%
  group_by(sona_id) %>%
  summarize(
    Age = first(na.omit(Age)),
    Gender = first(na.omit(Gender)),
    Education = first(na.omit(Education)),
    Race = list(flatten_chr(Race)),
    .groups = 'drop'
  ) %>%
  # Remove NAs from Race and apply conditions
  mutate(
    Race = map_chr(Race, ~{
      clean_race <- na.omit(.x)  # Remove NAs
      if (length(clean_race) == 0) {
        NA_character_  # No race info
      } else if (length(unique(clean_race)) > 1) {
        "Multiracial"  # Multiple races
      } else {
        unique(clean_race)  # Single race
      }
    })
  )

parsed_speaker %>%
  mutate(
    Gender_grouped = case_when(
      Gender %in% c("male", "Male") ~ "men",
      Gender %in% c("female", "Girl", "Female", "Female ") ~ "women",
      Gender %in% c("agender", "Nonbinary", "NonBinary") ~ "non-binary",
      TRUE ~ "other"  # Catch any unexpected entries
    )
  )%>%
  count(Gender_grouped) %>%
  mutate(percent = n/sum(n))

parsed_speaker %>% 
  mutate(Age = as.numeric(Age)) %>%
  summarize(mean_age = mean(Age), sd_age = sd(Age))

parsed_speaker %>% 
  mutate(Education = case_when(
    Education == "12-13" ~ 12.5,
    Education == "Freshman In College" ~ 11,
    TRUE ~ as.numeric(Education)
  )) %>%
  summarize(mean_ed = mean(Education), sd_ed = sd(Education))

parsed_speaker %>%
  count(Race) %>%
  mutate(percent = n/sum(n))
```

## listener

```{r}
listener_data = read_csv("../data/exp2/listener.csv") %>% 
  filter(typeoftrial %in% c("demo", "english")) %>% 
  # excluding second attempt of 61440, identified by a different timestamp 
  filter(subject != 43110) %>%
  select(sona_id, response) %>% filter(response != 0) %>%
  mutate(is_valid = map_lgl(response, ~tryCatch({
    fromJSON(.x)
    TRUE
  }, error = function(e) FALSE))) %>%
  filter(is_valid)

parsed_listener = listener_data %>%
  mutate(response = map(response, ~fromJSON(.x))) %>% 
  unnest_wider(response) %>%
  mutate(Race = map(Race, ~if (is.null(.x)) NA else .x)) %>%
  group_by(sona_id) %>%
  summarize(
    Age = first(na.omit(Age)),
    Gender = first(na.omit(Gender)),
    Education = first(na.omit(Education)),
    Race = list(flatten_chr(Race)),
    English = first(na.omit(English)),
    .groups = 'drop'
  ) %>%
  # Remove NAs from Race and apply conditions
  mutate(
    Race = map_chr(Race, ~{
      clean_race <- na.omit(.x)  # Remove NAs
      if (length(clean_race) == 0) {
        NA_character_  # No race info
      } else if (length(unique(clean_race)) > 1) {
        "Multiracial"  # Multiple races
      } else {
        unique(clean_race)  # Single race
      }
    })
  )

parsed_listener %>%
  mutate(
    Gender_grouped = case_when(
      Gender %in% c("male", "Male") ~ "men",
      Gender %in% c("female", "Female", "woman") ~ "women",
      Gender %in% c("genderfluid", "Nonbinary", "NonBinary") ~ "non-binary",
      TRUE ~ "other"  # Catch any unexpected entries
    )
  )%>%
  count(Gender_grouped) %>%
  mutate(percent = n/sum(n))

parsed_listener %>%
  count(Race) %>%
  mutate(percent = n/sum(n))

parsed_listener %>% 
  mutate(Age = as.numeric(Age)) %>%
  summarize(mean_age = mean(Age), sd_age = sd(Age))

parsed_listener %>% 
  mutate(Education = case_when(
    Education == "13 years" ~ 13,
    Education == "12 years" ~ 12,
    Education == "14 years" ~ 14,
    TRUE ~ as.numeric(Education)
  )) %>%
  summarize(mean_ed = mean(Education), sd_ed = sd(Education))
```




<!-- # extra -->

<!-- ```{r} -->
<!-- ## create new targets, with list of clues as a new column -->

<!-- targets_and_clues = read_csv("data/exp3/cleaned.csv")  %>% -->
<!--   select(word1, word2, Experiment, boardnames,wordpair,correctedClue) -->

<!-- clues_wide =targets_and_clues %>% -->
<!--   group_by(wordpair) %>% -->
<!--   summarise(clues = paste(unique(correctedClue), collapse = ',')) -->

<!-- targets_and_clues = targets_and_clues %>% select(-correctedClue)%>% unique() %>% -->
<!--   left_join(clues_wide) -->

<!-- write.csv(targets_and_clues, file = "data/exp3/revised_targets.csv", row.names = FALSE) -->

<!-- ``` -->

<!-- ## board comparison -->

<!-- ```{r} -->


<!-- clean_and_unite <- function(column) { -->
<!--   column %>% -->
<!--     mutate_all(~ str_remove_all(., "\\[|\\]|\"")) -->
<!-- } -->

<!-- boards = readxl::read_excel("../data/all_boards.xlsx") %>% -->
<!--   clean_and_unite() %>% -->
<!--   mutate(exp1 = str_split(gsub(",\\s*", " ", exp1), "\\s+"), -->
<!--          exp2 = str_split(gsub(",\\s*", " ", exp2), "\\s+"), -->
<!--          exp3 = str_split(gsub(",\\s*", " ", exp3), "\\s+")) %>% -->
<!--   mutate(e1e3 = map2_lgl(exp1, exp3, ~ identical(sort(tolower(.x)), sort(tolower(.y)))), -->
<!--          e1e2 = map2_lgl(exp1, exp2, ~ identical(sort(tolower(.x)), sort(tolower(.y)))), -->
<!--          e2e3 = map2_lgl(exp2, exp3, ~ identical(sort(tolower(.x)), sort(tolower(.y)))), -->
<!--          in_e1_not_e2 = map2(exp1, exp2, ~ setdiff(tolower(.x), tolower(.y))), -->
<!--          in_e2_not_e1 = map2(exp1, exp2, ~ setdiff(tolower(.y), tolower(.x))), -->
<!--          in_e1_not_e3 = map2(exp1, exp3, ~ setdiff(tolower(.x), tolower(.y))), -->
<!--          in_e3_not_e1 = map2(exp1, exp3, ~ setdiff(tolower(.y), tolower(.x))), -->
<!--          in_e2_not_e3 = map2(exp2, exp3, ~ setdiff(tolower(.x), tolower(.y))), -->
<!--          in_e3_not_e2 = map2(exp2, exp3, ~ setdiff(tolower(.y), tolower(.x)))) -->

<!-- View(boards %>% filter(!e1e3)) -->
<!-- View(boards %>% filter(!e1e2, !is.na(exp2))) -->
<!-- View(boards %>% filter(!e2e3, !is.na(exp2))) -->
<!-- ``` -->


